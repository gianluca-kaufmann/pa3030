#!/usr/bin/env python3
"""
Satellite Embeddings (1 km) - Quick Visualization

Loads a multi-band embedding GeoTIFF from data/ready/embeddings, computes a
3-component PCA (via NumPy SVD) to create an RGB composite, and saves a PNG.

Inputs: the first .tif file found in data/ready/embeddings
Output: outputs/Figures/alphaearth_vis/embeddings_2020_tile_rgb.png
"""

import numpy as np
import rasterio
from pathlib import Path
import matplotlib.pyplot as plt


# Paths
PROJECT_ROOT = Path("/Users/gianluca/Desktop/Master's Thesis/code")
EMBED_DIR = PROJECT_ROOT / "data" / "ready" / "embeddings"
OUT_DIR = PROJECT_ROOT / "outputs" / "Figures" / "alphaearth_vis"
OUT_DIR.mkdir(parents=True, exist_ok=True)


def find_all_tifs(directory: Path) -> list[Path]:
    tifs = sorted(directory.glob("*.tif"))
    if not tifs:
        raise FileNotFoundError(f"No .tif found in {directory}")
    return tifs

def get_tile_stats(tif_path: Path) -> dict:
    """Get basic stats about a tile file."""
    with rasterio.open(tif_path) as src:
        bounds = src.bounds
        shape = src.shape
        bands = src.count
        crs = src.crs
        
        # Convert Web Mercator bounds to lat/lon for geographic info
        from rasterio.warp import transform_bounds
        if crs.to_string() == 'EPSG:3857':
            # Transform from Web Mercator to WGS84
            min_lon, min_lat, max_lon, max_lat = transform_bounds(crs, 'EPSG:4326', 
                                                                bounds.left, bounds.bottom, 
                                                                bounds.right, bounds.top)
            
            # Calculate approximate area in km¬≤ using lat/lon
            # More accurate calculation considering Earth's curvature
            import math
            R = 6371  # Earth radius in km
            
            # Convert to radians
            lat1_rad = math.radians(min_lat)
            lat2_rad = math.radians(max_lat)
            delta_lat = math.radians(max_lat - min_lat)
            delta_lon = math.radians(max_lon - min_lon)
            
            # Haversine formula for width (at average latitude)
            avg_lat = (min_lat + max_lat) / 2
            width_km = R * delta_lon * math.cos(math.radians(avg_lat))
            height_km = R * delta_lat
            
            area_km2 = width_km * height_km
        else:
            # Fallback for other CRS
            width_km = (bounds.right - bounds.left) / 1000
            height_km = (bounds.top - bounds.bottom) / 1000
            area_km2 = width_km * height_km
            min_lat, min_lon = 0, 0
            max_lat, max_lon = 0, 0
        
        return {
            'file': tif_path.name,
            'bounds': bounds,
            'shape': shape,
            'bands': bands,
            'crs': str(crs),
            'width_km': width_km,
            'height_km': height_km,
            'area_km2': area_km2,
            'center_lat': (min_lat + max_lat) / 2,
            'center_lon': (min_lon + max_lon) / 2,
            'min_lat': min_lat,
            'max_lat': max_lat,
            'min_lon': min_lon,
            'max_lon': max_lon
        }


def _replace_nans_with_band_means(X: np.ndarray) -> np.ndarray:
    band_means = np.nanmean(X, axis=1, keepdims=True)
    nan_mask = np.isnan(X)
    if np.any(nan_mask):
        # Broadcast band means to nan positions
        rows, cols = np.where(nan_mask)
        X[rows, cols] = band_means[rows, 0]
    return X


def _percentile_stretch(img: np.ndarray, pmin: float = 2.0, pmax: float = 98.0) -> np.ndarray:
    vmin = np.percentile(img, pmin)
    vmax = np.percentile(img, pmax)
    if vmax <= vmin:
        vmax = vmin + 1e-6
    out = np.clip((img - vmin) / (vmax - vmin), 0, 1)
    return out


def _gray_world_balance(rgb: np.ndarray) -> np.ndarray:
    # Simple gray-world color balance to avoid color casts
    # rgb in [0,1], shape (H, W, 3)
    means = rgb.reshape(-1, 3).mean(axis=0) + 1e-6
    scale = means.mean() / means
    balanced = np.clip(rgb * scale, 0, 1)
    return balanced


def compute_pca_rgb_zscore(data: np.ndarray) -> np.ndarray:
    """PCA RGB after band-wise z-score standardization and gray-world balance.

    Args:
        data: (bands, height, width)
    Returns:
        (height, width, 3) uint8 RGB
    """
    bands, height, width = data.shape
    X = data.reshape(bands, height * width).astype(np.float32)
    X = _replace_nans_with_band_means(X)

    # Band-wise z-score
    mean = X.mean(axis=1, keepdims=True)
    std = X.std(axis=1, keepdims=True) + 1e-6
    Xz = (X - mean) / std

    # PCA (SVD) and take first 3 components across pixels
    U, S, Vt = np.linalg.svd(Xz, full_matrices=False)
    pcs = Vt[:3, :].reshape(3, height, width)

    # Percentile stretch per channel, then gray-world balance
    channels = [_percentile_stretch(pcs[i]) for i in range(3)]
    rgb = np.stack(channels, axis=-1)
    rgb = _gray_world_balance(rgb)
    return (rgb * 255).astype(np.uint8)


def compute_pca_rgb_unitvec(data: np.ndarray) -> np.ndarray:
    """PCA RGB after per-pixel L2 normalization (emphasizes angular structure).

    Args:
        data: (bands, height, width)
    Returns:
        (height, width, 3) uint8 RGB
    """
    bands, height, width = data.shape
    X = data.reshape(bands, height * width).astype(np.float32)
    X = _replace_nans_with_band_means(X)

    # Per-pixel L2 normalization
    norms = np.linalg.norm(X, axis=0, keepdims=True) + 1e-6
    Xu = X / norms

    U, S, Vt = np.linalg.svd(Xu, full_matrices=False)
    pcs = Vt[:3, :].reshape(3, height, width)

    channels = [_percentile_stretch(pcs[i]) for i in range(3)]
    rgb = np.stack(channels, axis=-1)
    rgb = _gray_world_balance(rgb)
    return (rgb * 255).astype(np.uint8)


def compute_magnitude_heatmap(data: np.ndarray) -> np.ndarray:
    """Embedding magnitude (L2 norm across bands) as a grayscale heatmap uint8."""
    bands, height, width = data.shape
    X = data.reshape(bands, height * width).astype(np.float32)
    X = _replace_nans_with_band_means(X)
    mags = np.linalg.norm(X, axis=0).reshape(height, width)
    heat = _percentile_stretch(mags)
    return (heat * 255).astype(np.uint8)


def check_data_quality(tif_path: Path) -> dict:
    """Check data quality for a tile."""
    with rasterio.open(tif_path) as src:
        data = src.read()  # (bands, height, width)
        
        bands, height, width = data.shape
        total_pixels = height * width
        
        # Check per-band statistics
        band_nan_counts = []
        band_zero_counts = []
        band_valid_counts = []
        band_means = []
        band_stds = []
        
        for b in range(bands):
            band_data = data[b]
            nan_count = np.isnan(band_data).sum()
            zero_count = (band_data == 0).sum()
            valid_count = (~np.isnan(band_data) & (band_data != 0)).sum()
            
            band_nan_counts.append(nan_count)
            band_zero_counts.append(zero_count)
            band_valid_counts.append(valid_count)
            
            valid_data = band_data[~np.isnan(band_data) & (band_data != 0)]
            if len(valid_data) > 0:
                band_means.append(np.mean(valid_data))
                band_stds.append(np.std(valid_data))
            else:
                band_means.append(0)
                band_stds.append(0)
        
        # Overall statistics
        total_nans = sum(band_nan_counts)
        total_zeros = sum(band_zero_counts)
        total_valid = sum(band_valid_counts)
        total_values = bands * total_pixels
        
        return {
            'file': tif_path.name,
            'bands': bands,
            'pixels': total_pixels,
            'total_values': total_values,
            'total_nans': total_nans,
            'total_zeros': total_zeros,
            'total_valid': total_valid,
            'nan_percentage': (total_nans / total_values) * 100,
            'zero_percentage': (total_zeros / total_values) * 100,
            'valid_percentage': (total_valid / total_values) * 100,
            'band_nan_counts': band_nan_counts,
            'band_valid_counts': band_valid_counts,
            'band_means': band_means,
            'band_stds': band_stds,
            'avg_band_mean': np.mean([m for m in band_means if m != 0]) if any(m != 0 for m in band_means) else 0,
            'avg_band_std': np.mean([s for s in band_stds if s != 0]) if any(s != 0 for s in band_stds) else 0
        }

def print_tile_statistics(tif_paths: list[Path]) -> None:
    """Print statistics about all tiles."""
    print(f"üìä TILE STATISTICS ({len(tif_paths)} tiles)")
    print("=" * 80)
    
    all_stats = []
    total_area = 0
    
    for tif_path in tif_paths:
        stats = get_tile_stats(tif_path)
        all_stats.append(stats)
        total_area += stats['area_km2']
    
    # Sort by center coordinates for better overview
    all_stats.sort(key=lambda x: (x['center_lat'], x['center_lon']))
    
    print(f"{'Tile':<35} {'Center (lat,lon)':<20} {'Size (km)':<15} {'Area (km¬≤)':<12} {'Bands':<6}")
    print("-" * 80)
    
    for stats in all_stats:
        print(f"{stats['file']:<35} "
              f"({stats['center_lat']:6.2f}, {stats['center_lon']:7.2f}) "
              f"{stats['width_km']:6.1f}x{stats['height_km']:5.1f} "
              f"{stats['area_km2']:10.0f} "
              f"{stats['bands']:6}")
    
    print("-" * 80)
    print(f"Total coverage: {total_area:,.0f} km¬≤")
    print(f"Average tile size: {total_area/len(all_stats):,.0f} km¬≤")
    print(f"Geographic bounds:")
    
    # Calculate overall bounds using proper lat/lon coordinates
    min_lat = min(s['min_lat'] for s in all_stats)
    max_lat = max(s['max_lat'] for s in all_stats)
    min_lon = min(s['min_lon'] for s in all_stats)
    max_lon = max(s['max_lon'] for s in all_stats)
    
    print(f"  Latitude: {min_lat:7.2f} to {max_lat:7.2f} ({max_lat-min_lat:6.2f}¬∞)")
    print(f"  Longitude: {min_lon:7.2f} to {max_lon:7.2f} ({max_lon-min_lon:6.2f}¬∞)")
    
    # Show spatial resolution info
    if all_stats:
        first_stats = all_stats[0]
        print(f"  Spatial resolution: ~{first_stats['width_km']/first_stats['shape'][1]:.1f} km/pixel")
        print(f"  Tile dimensions: {first_stats['shape'][1]} x {first_stats['shape'][0]} pixels")
    print()

def visualize_all_tiles(tif_paths: list[Path]) -> None:
    """Create visualizations for all tiles."""
    print(f"üé® Creating visualizations for {len(tif_paths)} tiles...")
    
    for i, tif_path in enumerate(tif_paths):
        print(f"   Processing tile {i+1}/{len(tif_paths)}: {tif_path.name}")
        
        with rasterio.open(tif_path) as src:
            data = src.read()  # (bands, height, width)
        
        # Create unique filenames based on tile name
        tile_name = tif_path.stem  # filename without extension
        
        # Visual 1: PCA on z-scored bands (balanced)
        rgb_z = compute_pca_rgb_zscore(data)
        out_file_z = OUT_DIR / f"{tile_name}_pca_zscore_rgb.png"
        plt.imsave(out_file_z.as_posix(), rgb_z)
        
        # Visual 2: PCA on unit-vector (angular) embeddings (balanced)
        rgb_u = compute_pca_rgb_unitvec(data)
        out_file_u = OUT_DIR / f"{tile_name}_pca_unitvec_rgb.png"
        plt.imsave(out_file_u.as_posix(), rgb_u)
        
        # Visual 3: Magnitude heatmap
        mag = compute_magnitude_heatmap(data)
        out_file_m = OUT_DIR / f"{tile_name}_magnitude.png"
        plt.imsave(out_file_m.as_posix(), mag, cmap='magma')
    
    print(f"‚úÖ Created {len(tif_paths) * 3} visualizations in {OUT_DIR}")

def print_detailed_tile_report(tif_paths: list[Path]) -> None:
    """Print detailed statistics report for each tile."""
    print(f"\nüìã DETAILED TILE REPORT")
    print("=" * 100)
    
    all_tile_info = []
    
    for idx, tif_path in enumerate(tif_paths, 1):
        print(f"\n{'='*100}")
        print(f"TILE {idx}/{len(tif_paths)}: {tif_path.name}")
        print(f"{'='*100}")
        
        # Get geographic stats
        geo_stats = get_tile_stats(tif_path)
        
        # Get quality stats
        quality_stats = check_data_quality(tif_path)
        
        # Combine info
        tile_info = {**geo_stats, **quality_stats}
        all_tile_info.append(tile_info)
        
        # Print location information
        print(f"\nüìç LOCATION:")
        print(f"   Center coordinates:  {tile_info['center_lat']:8.4f}¬∞, {tile_info['center_lon']:8.4f}¬∞")
        print(f"   Latitude range:      {tile_info['min_lat']:8.4f}¬∞ to {tile_info['max_lat']:8.4f}¬∞  ({tile_info['max_lat']-tile_info['min_lat']:6.2f}¬∞ span)")
        print(f"   Longitude range:     {tile_info['min_lon']:8.4f}¬∞ to {tile_info['max_lon']:8.4f}¬∞  ({tile_info['max_lon']-tile_info['min_lon']:6.2f}¬∞ span)")
        
        # Print size information
        print(f"\nüìê SIZE:")
        print(f"   Physical dimensions: {tile_info['width_km']:7.1f} km √ó {tile_info['height_km']:7.1f} km")
        print(f"   Area coverage:       {tile_info['area_km2']:10,.0f} km¬≤")
        print(f"   Pixel dimensions:    {tile_info['shape'][1]:,} √ó {tile_info['shape'][0]:,} pixels")
        print(f"   Total pixels:        {tile_info['pixels']:,}")
        print(f"   Pixel resolution:    ~{tile_info['width_km']/tile_info['shape'][1]:.2f} km/pixel")
        
        # Print data quality information
        print(f"\nüî¨ DATA QUALITY:")
        print(f"   Number of bands:     {tile_info['bands']}")
        print(f"   Total data points:   {tile_info['total_values']:,} ({tile_info['bands']} bands √ó {tile_info['pixels']:,} pixels)")
        print(f"   Valid data points:   {tile_info['total_valid']:,} ({tile_info['valid_percentage']:.2f}%)")
        print(f"   NaN data points:     {tile_info['total_nans']:,} ({tile_info['nan_percentage']:.2f}%)")
        print(f"   Zero data points:    {tile_info['total_zeros']:,} ({tile_info['zero_percentage']:.2f}%)")
        
        # Calculate valid pixels (pixels where at least one band has valid data)
        valid_pixels = tile_info['total_valid'] // tile_info['bands'] if tile_info['bands'] > 0 else 0
        valid_pixel_pct = (valid_pixels / tile_info['pixels']) * 100 if tile_info['pixels'] > 0 else 0
        print(f"   Valid pixels:        ~{valid_pixels:,} (~{valid_pixel_pct:.1f}% of pixels have some valid data)")
        
        # Print embedding statistics
        print(f"\nüìä EMBEDDING STATISTICS:")
        print(f"   Mean (across bands): {tile_info['avg_band_mean']:9.6f}")
        print(f"   Std (across bands):  {tile_info['avg_band_std']:9.6f}")
        
        # Quality assessment
        if tile_info['valid_percentage'] > 75:
            status = "‚úÖ EXCELLENT - High data coverage"
        elif tile_info['valid_percentage'] > 50:
            status = "‚úÖ GOOD - Adequate data coverage"
        elif tile_info['valid_percentage'] > 25:
            status = "‚ö†Ô∏è  FAIR - Moderate data coverage"
        else:
            status = "‚ö†Ô∏è  POOR - Low data coverage"
        
        print(f"\nüéØ QUALITY ASSESSMENT: {status}")
    
    # Summary table
    print(f"\n{'='*100}")
    print(f"SUMMARY TABLE - ALL TILES")
    print(f"{'='*100}\n")
    
    print(f"{'Tile':<40} {'Center (Lat,Lon)':<22} {'Area (km¬≤)':<14} {'Pixels':<12} {'Valid %':<10}")
    print("-" * 100)
    
    for info in all_tile_info:
        print(f"{info['file']:<40} "
              f"({info['center_lat']:7.3f}, {info['center_lon']:8.3f}) "
              f"{info['area_km2']:>12,.0f}  "
              f"{info['pixels']:>10,}  "
              f"{info['valid_percentage']:>8.1f}%")
    
    print("-" * 100)
    
    # Overall statistics
    total_area = sum(info['area_km2'] for info in all_tile_info)
    total_pixels = sum(info['pixels'] for info in all_tile_info)
    total_valid = sum(info['total_valid'] for info in all_tile_info)
    total_values = sum(info['total_values'] for info in all_tile_info)
    overall_valid_pct = (total_valid / total_values) * 100 if total_values > 0 else 0
    
    print(f"\nOVERALL STATISTICS:")
    print(f"   Total tiles:         {len(all_tile_info)}")
    print(f"   Total area:          {total_area:,.0f} km¬≤")
    print(f"   Total pixels:        {total_pixels:,}")
    print(f"   Overall valid data:  {overall_valid_pct:.2f}%")
    print(f"   Geographic extent:   {max(info['max_lat'] for info in all_tile_info) - min(info['min_lat'] for info in all_tile_info):.2f}¬∞ lat √ó "
          f"{max(info['max_lon'] for info in all_tile_info) - min(info['min_lon'] for info in all_tile_info):.2f}¬∞ lon")
    
    print()

def print_data_quality(tif_paths: list[Path]) -> None:
    """Print data quality statistics for all tiles."""
    print(f"üîç DATA QUALITY CHECK ({len(tif_paths)} tiles)")
    print("=" * 100)
    
    quality_stats = []
    for tif_path in tif_paths:
        print(f"   Analyzing {tif_path.name}...", end=' ')
        stats = check_data_quality(tif_path)
        quality_stats.append(stats)
        print("‚úì")
    
    print()
    print(f"{'Tile':<35} {'Valid %':<10} {'NaN %':<10} {'Zero %':<10} {'Avg Mean':<12} {'Avg Std':<12}")
    print("-" * 100)
    
    for stats in quality_stats:
        status = "‚úÖ" if stats['valid_percentage'] > 50 else "‚ö†Ô∏è" if stats['valid_percentage'] > 10 else "‚ùå"
        print(f"{stats['file']:<35} "
              f"{stats['valid_percentage']:>8.2f}% "
              f"{stats['nan_percentage']:>8.2f}% "
              f"{stats['zero_percentage']:>8.2f}% "
              f"{stats['avg_band_mean']:>10.4f}  "
              f"{stats['avg_band_std']:>10.4f}  "
              f"{status}")
    
    print("-" * 100)
    
    # Overall summary
    total_valid = sum(s['total_valid'] for s in quality_stats)
    total_values = sum(s['total_values'] for s in quality_stats)
    overall_valid_pct = (total_valid / total_values) * 100
    
    print(f"Overall valid data: {overall_valid_pct:.2f}%")
    print(f"Total pixels across all tiles: {sum(s['pixels'] for s in quality_stats):,}")
    print(f"Total bands: {quality_stats[0]['bands'] if quality_stats else 0}")
    
    # Check for problem bands (bands with mostly NaN/zero across all tiles)
    if quality_stats:
        num_bands = quality_stats[0]['bands']
        print(f"\nüî¨ Per-band quality (averaged across all tiles):")
        
        problem_bands = []
        for b in range(num_bands):
            band_valid_counts = [s['band_valid_counts'][b] for s in quality_stats]
            band_pixels = quality_stats[0]['pixels'] * len(quality_stats)
            band_valid_pct = (sum(band_valid_counts) / band_pixels) * 100
            
            if band_valid_pct < 50:
                problem_bands.append((b, band_valid_pct))
        
        if problem_bands:
            print(f"   ‚ö†Ô∏è Found {len(problem_bands)} bands with <50% valid data:")
            for band_idx, valid_pct in problem_bands[:10]:  # Show first 10
                print(f"      Band {band_idx}: {valid_pct:.1f}% valid")
            if len(problem_bands) > 10:
                print(f"      ... and {len(problem_bands) - 10} more")
        else:
            print(f"   ‚úÖ All bands have >50% valid data across tiles")
    
    print()

def main():
    # Find all tile files (exclude the test tile)
    all_tifs = find_all_tifs(EMBED_DIR)
    tile_tifs = [tif for tif in all_tifs if 'tile_test' not in tif.name]
    
    if not tile_tifs:
        print("‚ùå No tile files found (excluding test tile)")
        return
    
    print(f"üìÅ Found {len(tile_tifs)} embedding tiles")
    print()
    
    # Print quick overview statistics
    print_tile_statistics(tile_tifs)
    
    # Print detailed report for each tile
    print_detailed_tile_report(tile_tifs)
    
    # Ask user if they want to proceed with visualizations
    print("\nüí≠ Do you want to create visualizations?")
    print("   (This will create 36 PNG files)")
    response = input("   Continue? [y/N]: ").strip().lower()
    
    if response in ['y', 'yes']:
        # Create visualizations for all tiles
        visualize_all_tiles(tile_tifs)
    else:
        print("   Skipping visualizations.")


if __name__ == "__main__":
    main()


