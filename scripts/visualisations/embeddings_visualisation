#!/usr/bin/env python3
"""
Multi-Temporal Satellite Embeddings (2018-2024) - Visualization

Creates visualizations for the merged multi-temporal embedding file (448 bands = 64 bands √ó 7 years).
Generates PCA composites and heatmaps for each year to show temporal changes.

Input: SatelliteEmbeddings_SA_1km_2018-2024_multitemporal.tif
Output: outputs/Figures/embeddings_vis/embeddings_*.png
"""

import numpy as np
import rasterio
from pathlib import Path
import matplotlib.pyplot as plt
from typing import Tuple, List
import matplotlib.gridspec as gridspec

# Paths
PROJECT_ROOT = Path("/Users/gianluca/Desktop/Master's Thesis/code")
EMBED_DIR = PROJECT_ROOT / "data" / "ready" / "embeddings"
EMBEDDINGS_FILE = EMBED_DIR / "SatelliteEmbeddings_SA_1km_2018-2024_multitemporal.tif"
OUT_DIR = PROJECT_ROOT / "outputs" / "Figures" / "embeddings_vis"
OUT_DIR.mkdir(parents=True, exist_ok=True)

# Years in the dataset
YEARS = [2018, 2019, 2020, 2021, 2022, 2023, 2024]
BANDS_PER_YEAR = 64


def log_progress(message: str):
    """Simple logging function."""
    print(f"üìä {message}")


def load_multitemporal_data(downsample: bool = True, 
                            target_size: Tuple[int, int] = (2000, 2000)) -> Tuple[np.ndarray, dict]:
    """
    Load the multi-temporal embeddings file.
    
    Returns:
        data: Array of shape (bands, height, width) = (448, H, W)
        metadata: Dictionary with file information
    """
    log_progress(f"Loading: {EMBEDDINGS_FILE.name}")
    
    with rasterio.open(EMBEDDINGS_FILE) as src:
        # Get metadata
        metadata = {
            'bands': src.count,
            'shape': src.shape,
            'crs': src.crs,
            'bounds': src.bounds,
            'transform': src.transform,
            'width': src.width,
            'height': src.height
        }
        
        log_progress(f"  Dimensions: {src.width} √ó {src.height}")
        log_progress(f"  Bands: {src.count}")
        log_progress(f"  CRS: {src.crs}")
        
        # Load data
        if downsample and (src.width > target_size[0] or src.height > target_size[1]):
            # Calculate downsample factors
            scale_x = src.width / target_size[0]
            scale_y = src.height / target_size[1]
            scale = max(scale_x, scale_y)
            
            new_width = int(src.width / scale)
            new_height = int(src.height / scale)
            
            log_progress(f"  Downsampling to ~{new_width} √ó {new_height} for visualization...")
            
            # Read downsampled data
            data = src.read(
                out_shape=(src.count, new_height, new_width),
                resampling=rasterio.enums.Resampling.average
            )
            
            log_progress(f"  Loaded downsampled data: {data.shape}")
        else:
            log_progress(f"  Loading full resolution...")
            data = src.read()
            log_progress(f"  Loaded data: {data.shape}")
    
    return data, metadata


def get_year_data(data: np.ndarray, year: int) -> np.ndarray:
    """
    Extract data for a specific year from multi-temporal array.
    
    Args:
        data: Full array (448, H, W)
        year: Year to extract (2018-2024)
    
    Returns:
        year_data: Array (64, H, W) for that year
    """
    year_idx = YEARS.index(year)
    band_start = year_idx * BANDS_PER_YEAR
    band_end = band_start + BANDS_PER_YEAR
    return data[band_start:band_end, :, :]


def compute_pca_rgb(data: np.ndarray, normalize: str = 'zscore') -> np.ndarray:
    """
    Compute PCA and create RGB composite from first 3 components.
    
    Args:
        data: (bands, height, width)
        normalize: 'zscore' or 'unitvec'
    
    Returns:
        rgb: (height, width, 3) RGB image in [0, 1]
    """
    bands, height, width = data.shape
    
    # Reshape: (bands, pixels)
    X = data.reshape(bands, -1)
    
    # Handle NaNs by replacing with band means
    nan_mask = np.isnan(X)
    if np.any(nan_mask):
        band_means = np.nanmean(X, axis=1, keepdims=True)
        rows, cols = np.where(nan_mask)
        X[rows, cols] = band_means[rows, 0]
    
    # Normalize
    if normalize == 'zscore':
        # Z-score normalization
        means = np.mean(X, axis=1, keepdims=True)
        stds = np.std(X, axis=1, keepdims=True)
        stds = np.where(stds == 0, 1, stds)  # Avoid division by zero
        X = (X - means) / stds
    elif normalize == 'unitvec':
        # Unit vector normalization
        norms = np.linalg.norm(X, axis=0, keepdims=True)
        norms = np.where(norms == 0, 1, norms)
        X = X / norms
    
    # Transpose for PCA: (pixels, bands)
    X = X.T
    
    # Center the data
    X_mean = np.mean(X, axis=0)
    X_centered = X - X_mean
    
    # Compute SVD
    U, S, Vt = np.linalg.svd(X_centered, full_matrices=False)
    
    # First 3 principal components: U[:, :3]
    pc = U[:, :3]  # (pixels, 3)
    
    # Reshape to image: (height, width, 3)
    rgb = pc.reshape(height, width, 3)
    
    # Normalize to [0, 1] for each channel
    for c in range(3):
        channel = rgb[:, :, c]
        vmin, vmax = np.percentile(channel[~np.isnan(channel)], [2, 98])
        rgb[:, :, c] = np.clip((channel - vmin) / (vmax - vmin), 0, 1)
    
    return rgb


def compute_magnitude(data: np.ndarray) -> np.ndarray:
    """
    Compute L2 norm (magnitude) across all bands.
    
    Args:
        data: (bands, height, width)
    
    Returns:
        magnitude: (height, width)
    """
    # Compute L2 norm across band dimension
    mag = np.linalg.norm(data, axis=0)
    
    # Normalize to [0, 1]
    mag_clean = mag[~np.isnan(mag)]
    if len(mag_clean) > 0:
        vmin, vmax = np.percentile(mag_clean, [2, 98])
        mag = np.clip((mag - vmin) / (vmax - vmin), 0, 1)
    
    return mag


def create_year_visualizations(data: np.ndarray) -> None:
    """
    Create visualizations for each year.
    
    For each year, creates:
    - PCA RGB composite (z-score)
    - Magnitude heatmap
    """
    log_progress("\n" + "=" * 80)
    log_progress("CREATING PER-YEAR VISUALIZATIONS")
    log_progress("=" * 80)
    
    for year in YEARS:
        log_progress(f"\nProcessing {year}...")
        
        # Extract year data
        year_data = get_year_data(data, year)
        
        # 1. PCA RGB
        log_progress(f"  Computing PCA RGB...")
        rgb = compute_pca_rgb(year_data, normalize='zscore')
        out_file = OUT_DIR / f"embeddings_{year}_pca_rgb.png"
        plt.imsave(out_file, rgb)
        log_progress(f"  ‚úÖ Saved: {out_file.name}")
        
        # 2. Magnitude heatmap
        log_progress(f"  Computing magnitude...")
        mag = compute_magnitude(year_data)
        out_file = OUT_DIR / f"embeddings_{year}_magnitude.png"
        plt.imsave(out_file, mag, cmap='magma')
        log_progress(f"  ‚úÖ Saved: {out_file.name}")


def create_temporal_comparison_grid(data: np.ndarray) -> None:
    """
    Create a grid showing PCA RGB for all years side-by-side.
    """
    log_progress("\n" + "=" * 80)
    log_progress("CREATING TEMPORAL COMPARISON GRID")
    log_progress("=" * 80)
    
    # Create figure with subplots
    fig = plt.figure(figsize=(20, 6))
    gs = gridspec.GridSpec(1, 7, figure=fig, wspace=0.05, hspace=0.05)
    
    for idx, year in enumerate(YEARS):
        log_progress(f"  Adding {year} to grid...")
        
        # Get year data and compute PCA
        year_data = get_year_data(data, year)
        rgb = compute_pca_rgb(year_data, normalize='zscore')
        
        # Add to subplot
        ax = fig.add_subplot(gs[0, idx])
        ax.imshow(rgb)
        ax.set_title(str(year), fontsize=14, fontweight='bold')
        ax.axis('off')
    
    # Save
    out_file = OUT_DIR / "embeddings_temporal_comparison_grid.png"
    plt.savefig(out_file, dpi=300, bbox_inches='tight')
    plt.close()
    
    log_progress(f"‚úÖ Saved: {out_file.name}")


def create_magnitude_temporal_grid(data: np.ndarray) -> None:
    """
    Create a grid showing magnitude for all years side-by-side.
    """
    log_progress("\n" + "=" * 80)
    log_progress("CREATING MAGNITUDE TEMPORAL COMPARISON")
    log_progress("=" * 80)
    
    # Create figure with subplots
    fig = plt.figure(figsize=(20, 6))
    gs = gridspec.GridSpec(1, 7, figure=fig, wspace=0.05, hspace=0.05)
    
    for idx, year in enumerate(YEARS):
        log_progress(f"  Adding {year} magnitude to grid...")
        
        # Get year data and compute magnitude
        year_data = get_year_data(data, year)
        mag = compute_magnitude(year_data)
        
        # Add to subplot
        ax = fig.add_subplot(gs[0, idx])
        im = ax.imshow(mag, cmap='magma')
        ax.set_title(str(year), fontsize=14, fontweight='bold')
        ax.axis('off')
    
    # Add colorbar
    fig.colorbar(im, ax=fig.get_axes(), orientation='horizontal', 
                 fraction=0.046, pad=0.04, label='Embedding Magnitude')
    
    # Save
    out_file = OUT_DIR / "embeddings_magnitude_temporal_grid.png"
    plt.savefig(out_file, dpi=300, bbox_inches='tight')
    plt.close()
    
    log_progress(f"‚úÖ Saved: {out_file.name}")


def print_data_statistics(data: np.ndarray, metadata: dict) -> None:
    """Print statistics about the loaded data."""
    log_progress("\n" + "=" * 80)
    log_progress("DATA STATISTICS")
    log_progress("=" * 80)
    
    total_bands = data.shape[0]
    height = data.shape[1]
    width = data.shape[2]
    
    log_progress(f"Shape: ({total_bands}, {height}, {width})")
    log_progress(f"Years: {len(YEARS)} ({min(YEARS)}-{max(YEARS)})")
    log_progress(f"Bands per year: {BANDS_PER_YEAR}")
    
    # Count valid pixels
    total_pixels = height * width
    valid_pixels_per_band = np.sum(~np.isnan(data), axis=(1, 2))
    
    # Average coverage across all bands
    avg_coverage = np.mean(valid_pixels_per_band) / total_pixels * 100
    
    log_progress(f"Average coverage: {avg_coverage:.2f}%")
    
    # Per-year coverage
    log_progress("\nCoverage by year:")
    for year in YEARS:
        year_data = get_year_data(data, year)
        year_coverage = np.mean(np.sum(~np.isnan(year_data), axis=(1, 2))) / total_pixels * 100
        log_progress(f"  {year}: {year_coverage:.2f}%")


def main():
    print("\n" + "=" * 80)
    print("MULTI-TEMPORAL SATELLITE EMBEDDINGS VISUALIZATION")
    print("South America 1km Dataset (2018-2024)")
    print("=" * 80)
    print()
    
    # Check file exists
    if not EMBEDDINGS_FILE.exists():
        print(f"‚ùå Embeddings file not found: {EMBEDDINGS_FILE}")
        print()
        print("Please run the merge script first:")
        print("   python scripts/merging/merge_embeddings_total")
        return
    
    # Load data
    data, metadata = load_multitemporal_data(downsample=True, target_size=(2000, 2000))
    
    # Print statistics
    print_data_statistics(data, metadata)
    
    # Create visualizations
    create_year_visualizations(data)
    create_temporal_comparison_grid(data)
    create_magnitude_temporal_grid(data)
    
    # Summary
    print("\n" + "=" * 80)
    print("‚úÖ VISUALIZATION COMPLETE")
    print("=" * 80)
    
    total_files = len(YEARS) * 2 + 2  # 2 per year + 2 grids
    print(f"\nCreated {total_files} visualization files in {OUT_DIR}")
    
    print("\nPer-Year Visualizations:")
    for year in YEARS:
        print(f"   ‚Ä¢ embeddings_{year}_pca_rgb.png - PCA RGB composite")
        print(f"   ‚Ä¢ embeddings_{year}_magnitude.png - Magnitude heatmap")
    
    print("\nTemporal Comparison Visualizations:")
    print(f"   ‚Ä¢ embeddings_temporal_comparison_grid.png - All years PCA RGB")
    print(f"   ‚Ä¢ embeddings_magnitude_temporal_grid.png - All years magnitude")
    
    print("\nüí° TIPS:")
    print("   ‚Ä¢ PCA visualizations show spatial patterns in embedding space")
    print("   ‚Ä¢ Temporal grids allow visual comparison of changes over time")
    print("   ‚Ä¢ Magnitude shows overall embedding strength/intensity")
    print("   ‚Ä¢ Compare years to identify temporal changes in land use/cover")


if __name__ == "__main__":
    main()
