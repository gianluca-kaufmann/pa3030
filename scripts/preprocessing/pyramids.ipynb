{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a0578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import pyramid_gaussian, resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc5569a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35320feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. SYNTHETIC DATA GENERATION ---\n",
    "# We will create a 100x100 grid to represent our world.\n",
    "# Each pixel is a \"grid cell\" as described in your paper.\n",
    "MAP_SIZE = (100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "298379bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_data(size):\n",
    "    \"\"\"\n",
    "    Generates synthetic geospatial maps for our features and target.\n",
    "    This simulates the data you would source from GEE, WDPA, etc.\n",
    "    \"\"\"\n",
    "    print(f\"Creating synthetic {size} maps...\")\n",
    "    \n",
    "    # --- Target Variable (y) ---\n",
    "    # This is our \"World Database on Protected Areas (WDPA)\" layer\n",
    "    # 0 = Not Protected, 1 = Protected\n",
    "    existing_pas = np.zeros(size)\n",
    "    # Create a 30x30 \"National Park\" in a high-value area\n",
    "    existing_pas[10:40, 10:40] = 1\n",
    "    # Create a smaller 15x15 \"Reserve\"\n",
    "    existing_pas[70:85, 10:25] = 1\n",
    "\n",
    "    # --- Feature Variables (X) ---\n",
    "    \n",
    "    # Feature 1: Environmental Value (like NDVI)\n",
    "    # Hypothesis: PAs are MORE likely in high-value areas.\n",
    "    env_value_map = np.zeros(size)\n",
    "    # The \"National Park\" area is a high-value hotspot\n",
    "    env_value_map[5:45, 5:45] = 0.9\n",
    "    # The \"Reserve\" area is also high-value\n",
    "    env_value_map[65:90, 5:30] = 0.8\n",
    "    # Add another \"unprotected\" hotspot (where transition risk should be high)\n",
    "    env_value_map[20:40, 70:90] = 0.85\n",
    "    \n",
    "    # Feature 2: Economic Activity (like GDP / Night Lights)\n",
    "    # Hypothesis: PAs are LESS likely in high-GDP areas (high opportunity cost).\n",
    "    gdp_map = np.zeros(size)\n",
    "    # Create a 25x25 \"high-GDP city\" where protection is unlikely\n",
    "    gdp_map[50:75, 60:85] = 1.0 \n",
    "    # Add some noise\n",
    "    gdp_map += np.random.rand(*size) * 0.1\n",
    "    \n",
    "    # Feature 3: Population Density\n",
    "    # Hypothesis: PAs are LESS likely in high-population areas.\n",
    "    pop_map = np.zeros(size)\n",
    "    # Population is high near the city\n",
    "    pop_map[45:80, 55:90] = 0.8\n",
    "    # Add some \"villages\"\n",
    "    pop_map[15:25, 50:60] = 0.3\n",
    "    pop_map += np.random.rand(*size) * 0.05\n",
    "    \n",
    "    # Return a dictionary of feature maps and the single target map\n",
    "    feature_maps = {\n",
    "        'env_value': env_value_map,\n",
    "        'gdp': gdp_map,\n",
    "        'population': pop_map\n",
    "    }\n",
    "    \n",
    "    return feature_maps, existing_pas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
