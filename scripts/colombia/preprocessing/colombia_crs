#!/usr/bin/env python3
"""
Fix CRS for all Colombia rasters by warping to backbone grid (EPSG:3857).

This preprocessing step rewrites all input GeoTIFFs to match the backbone exactly:
- CRS: EPSG:3857 (true EPSG, not EngineeringCRS)
- Transform: Exact match to backbone transform
- Shape: Exact match to backbone shape
- Nodata: Preserved from source

This eliminates the need for complex CRS handling in the merge script.

Inputs:
- Source rasters in data/ready/<dataset>/ (or $SCRATCH/data/ready/<dataset>/ on cluster)
- Backbone: data/ready/backbone/colombia_GEE.tif

Outputs:
- Fixed rasters in data/ready/fixed_crs/<dataset>/ (mirrors source structure)
- Fixed backbone: data/ready/fixed_crs/backbone/colombia_GEE.tif

Usage:
    ./colombia_crs

Environment Requirements:
    - Use a conda-forge environment where rasterio, gdal, and proj all come
      from the same source (conda-forge) to avoid PROJ database conflicts.
    - On Euler cluster, the SLURM script (colombia_preprocessing.slurm) will:
      1. Module purge (unloads system GIS/GDAL/PROJ modules)
      2. Activate conda environment
      3. Set PROJ_LIB and GDAL_DATA to conda env paths
    
    To create/update conda environment:
        conda create -n master_thesis -c conda-forge python=3.11 rasterio gdal proj
        conda activate master_thesis
        pip install -r requirements.txt  # other dependencies
    
The script will automatically fall back to WKT/PROJ string methods if
the EPSG database is unavailable, but using conda-forge is strongly recommended.
"""

import sys
import os
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import re

import numpy as np
import rasterio
from rasterio.enums import Resampling
from rasterio.warp import reproject, calculate_default_transform
from rasterio.crs import CRS

# EPSG:3857 WKT string (Pseudo-Mercator) - works without PROJ database
EPSG_3857_WKT = """PROJCS["WGS 84 / Pseudo-Mercator",
    GEOGCS["WGS 84",
        DATUM["WGS_1984",
            SPHEROID["WGS 84",6378137,298.257223563,
                AUTHORITY["EPSG","7030"]],
            AUTHORITY["EPSG","6326"]],
        PRIMEM["Greenwich",0,
            AUTHORITY["EPSG","8901"]],
        UNIT["degree",0.0174532925199433,
            AUTHORITY["EPSG","9122"]],
        AUTHORITY["EPSG","4326"]],
    PROJECTION["Mercator_1SP"],
    PARAMETER["central_meridian",0],
    PARAMETER["scale_factor",1],
    PARAMETER["false_easting",0],
    PARAMETER["false_northing",0],
    UNIT["metre",1,
        AUTHORITY["EPSG","9001"]],
    AXIS["X",EAST],
    AXIS["Y",NORTH],
    EXTENSION["PROJ4","+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +wktext +no_defs"],
    AUTHORITY["EPSG","3857"]]"""


def log_progress(message: str, start_time: Optional[float] = None):
    """Log progress with optional timing."""
    if start_time:
        elapsed = time.time() - start_time
        print(f"[time] {message} ({elapsed:.1f}s)")
    else:
        print(f"[info] {message}")


def get_epsg_3857_crs():
    """
    Get EPSG:3857 CRS object with fallbacks for PROJ database issues.
    
    Tries multiple methods:
    1. CRS.from_epsg(3857) - standard method
    2. CRS.from_string("EPSG:3857") - string-based
    3. CRS.from_wkt(EPSG_3857_WKT) - WKT string (works without database)
    
    Returns:
        CRS object for EPSG:3857
    """
    # Method 1: Try from_epsg (requires PROJ database)
    try:
        return CRS.from_epsg(3857)
    except Exception as e1:
        log_progress(f"  Warning: CRS.from_epsg(3857) failed: {e1}")
        
        # Method 2: Try from_string
        try:
            return CRS.from_string("EPSG:3857")
        except Exception as e2:
            log_progress(f"  Warning: CRS.from_string('EPSG:3857') failed: {e2}")
            
            # Method 3: Use WKT string (works without PROJ database)
            try:
                return CRS.from_wkt(EPSG_3857_WKT)
            except Exception as e3:
                log_progress(f"  Warning: CRS.from_wkt() failed: {e3}")
                
                # Method 4: Use PROJ string directly
                try:
                    return CRS.from_string("+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +wktext +no_defs")
                except Exception as e4:
                    log_progress(f"  ERROR: All CRS creation methods failed!")
                    log_progress(f"    from_epsg: {e1}")
                    log_progress(f"    from_string: {e2}")
                    log_progress(f"    from_wkt: {e3}")
                    log_progress(f"    proj_string: {e4}")
                    raise RuntimeError("Could not create EPSG:3857 CRS. Please install conda-forge GDAL/PROJ.")

# Determine base path
SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPT_DIR.parent.parent.parent.parent

# Use $SCRATCH for data if on cluster, otherwise use project root
if "SCRATCH" in os.environ:
    DATA_ROOT = Path(os.environ["SCRATCH"]) / "data"
    READY_ROOT = DATA_ROOT / "ready"
else:
    DATA_ROOT = PROJECT_ROOT / "data"
    READY_ROOT = DATA_ROOT / "ready"

# Output directory for fixed CRS rasters
FIXED_CRS_ROOT = READY_ROOT / "fixed_crs"

# Datasets to process (exclude backbone, gdp, assetlevel, DynamicWorld, DW)
INCLUDE_DATASETS = [
    "WDPA", "HNTL", "NDVI", "GPW",
    "deforestation", "landcover", "WorldClim",
    "elevation", "slope", "oil_gas", "road_infrastructure",
    "GSN", "powerplants", "wildfire",
]


def load_backbone_template() -> Tuple[rasterio.DatasetReader, dict]:
    """
    Load backbone raster to get reference grid (CRS, transform, shape).
    
    Returns:
        (backbone_dataset, reference_profile)
    """
    log_progress("Loading backbone template...")
    
    backbone_paths = [
        READY_ROOT / "backbone" / "colombia_GEE.tif",
        DATA_ROOT / "backbone" / "colombia_GEE.tif",
    ]
    
    backbone_path = None
    for p in backbone_paths:
        if p.exists():
            backbone_path = p
            break
    
    if backbone_path is None:
        print("ERROR: colombia_GEE.tif not found.")
        print("\nChecked locations:")
        for p in backbone_paths:
            print(f"   - {p} (exists: {p.exists()})")
        sys.exit(1)
    
    backbone_src = rasterio.open(backbone_path)
    
    # Get EPSG:3857 CRS with fallbacks for PROJ database issues
    epsg_3857_crs = get_epsg_3857_crs()
    
    # Create reference profile
    ref_profile = {
        "crs": epsg_3857_crs,  # Force true EPSG:3857
        "transform": backbone_src.transform,
        "width": backbone_src.width,
        "height": backbone_src.height,
        "dtype": rasterio.float32,
        "nodata": np.nan,
        "compress": "lzw",
    }
    
    log_progress(f"Backbone template: {backbone_src.width}×{backbone_src.height}, CRS: EPSG:3857")
    log_progress(f"  Transform: {backbone_src.transform}")
    
    return backbone_src, ref_profile


def discover_raster_files() -> Dict[str, Dict[Optional[int], List[Path]]]:
    """
    Scan READY_ROOT and build catalog: {dataset: {year(or None): [paths]}}
    """
    log_progress("Scanning for raster files...")
    catalog: Dict[str, Dict[Optional[int], List[Path]]] = {}
    year_re = re.compile(r"(19|20)\d{2}")
    
    if not READY_ROOT.exists():
        print(f"ERROR: Data directory not found: {READY_ROOT}")
        sys.exit(1)
    
    total_files = 0
    for subdir in sorted([p for p in READY_ROOT.iterdir() if p.is_dir()]):
        dataset = subdir.name
        
        # Skip if not in include list
        if dataset not in INCLUDE_DATASETS and dataset != "backbone":
            continue
        
        catalog.setdefault(dataset, {})
        files_in_dataset = 0
        
        for tif in sorted(subdir.rglob("*.tif")):
            m = year_re.search(tif.name)
            year = int(m.group(0)) if m else None
            catalog[dataset].setdefault(year, []).append(tif)
            files_in_dataset += 1
            total_files += 1
        
        if files_in_dataset > 0:
            log_progress(f"  {dataset}: {files_in_dataset} files")
    
    log_progress(f"Total files found: {total_files}")
    return catalog


def warp_raster_to_backbone(
    src_path: Path,
    dst_path: Path,
    ref_profile: dict,
    dataset: str
) -> bool:
    """
    Warp a single raster to match backbone exactly (EPSG:3857, same transform/shape).
    
    Returns:
        True if successful, False otherwise
    """
    try:
        with rasterio.open(src_path) as src:
            # Check if already matches (fast path)
            # Use string comparison for CRS to avoid PROJ database issues
            src_crs_str = str(src.crs) if src.crs else ""
            ref_crs_str = str(ref_profile["crs"]) if ref_profile["crs"] else ""
            
            # Check alignment (shape, transform, and CRS match)
            crs_match = False
            try:
                # Try direct comparison first
                if src.crs is not None and ref_profile["crs"] is not None:
                    crs_match = src.crs == ref_profile["crs"]
            except:
                # Fallback to string comparison
                crs_match = ("3857" in src_crs_str and "3857" in ref_crs_str) or \
                           ("pseudo" in src_crs_str.lower() and "pseudo" in ref_crs_str.lower())
            
            if (crs_match and
                src.width == ref_profile["width"] and
                src.height == ref_profile["height"] and
                np.allclose(src.transform, ref_profile["transform"], atol=1e-6)):
                log_progress(f"    Already aligned: {src_path.name}")
                # Copy file directly if identical
                import shutil
                dst_path.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(src_path, dst_path)
                return True
            
            # Need to warp
            count = src.count
            src_nodata = src.nodata
            
            # Create destination array
            dst_data = np.full(
                (count, ref_profile["height"], ref_profile["width"]),
                ref_profile["nodata"],
                dtype=ref_profile["dtype"]
            )
            
            # Determine source CRS
            # For Pseudo-Mercator/EngineeringCRS/LOCAL_CS sources, force src_crs to match
            # ref_profile["crs"] so reprojection becomes same-CRS resampling only
            # (avoids CRS-operation lookup issues)
            src_crs = src.crs
            if src_crs is not None:
                try:
                    # Check if it's Pseudo-Mercator variant (EngineeringCRS, LOCAL_CS, etc.)
                    crs_str = str(src_crs).lower()
                    crs_name = str(src_crs.name).lower() if hasattr(src_crs, 'name') and src_crs.name else ""
                    crs_type = src_crs.__class__.__name__ if hasattr(src_crs, '__class__') else ""
                    
                    is_pseudo_mercator = (
                        "pseudo" in crs_name or 
                        "pseudo" in crs_str or
                        "3857" in str(src_crs) or
                        crs_type == "EngineeringCRS" or
                        crs_type == "LOCAL_CS" or
                        "local" in crs_str or
                        (crs_type == "EngineeringCRS" and "wgs 84" in crs_name)
                    )
                    
                    if is_pseudo_mercator:
                        # Force same-CRS resampling by using ref_profile CRS as source CRS
                        # This avoids CRS-operation lookup and treats it as resampling only
                        src_crs = ref_profile["crs"]
                        log_progress(f"    Detected Pseudo-Mercator variant ({crs_type}), using same-CRS resampling")
                except Exception as e:
                    # If we can't determine, log but continue
                    log_progress(f"    Warning: Could not determine CRS type: {e}")
            
            # If source CRS is None or invalid, use ref_profile CRS (same-CRS resampling)
            if src_crs is None:
                src_crs = ref_profile["crs"]
                log_progress(f"    Source CRS is None, using same-CRS resampling")
            
            # Reproject each band
            for b in range(1, count + 1):
                reproject(
                    source=rasterio.band(src, b),
                    destination=dst_data[b - 1],
                    src_transform=src.transform,
                    src_crs=src_crs,
                    src_nodata=src_nodata,
                    dst_transform=ref_profile["transform"],
                    dst_crs=ref_profile["crs"],
                    resampling=Resampling.nearest,
                    dst_nodata=ref_profile["nodata"],
                )
            
            # Write output
            dst_path.parent.mkdir(parents=True, exist_ok=True)
            with rasterio.open(
                dst_path,
                'w',
                driver='GTiff',
                count=count,
                width=ref_profile["width"],
                height=ref_profile["height"],
                dtype=ref_profile["dtype"],
                crs=ref_profile["crs"],
                transform=ref_profile["transform"],
                nodata=ref_profile["nodata"],
                compress=ref_profile["compress"],
            ) as dst:
                dst.write(dst_data)
            
            return True
            
    except Exception as e:
        log_progress(f"    ERROR warping {src_path.name}: {e}")
        return False


def process_backbone(backbone_src: rasterio.DatasetReader, ref_profile: dict) -> bool:
    """Process backbone file itself (ensure it's true EPSG:3857)."""
    log_progress("\nProcessing backbone...")
    
    backbone_path = Path(backbone_src.name)
    dst_path = FIXED_CRS_ROOT / "backbone" / backbone_path.name
    
    # Check if already correct CRS (use string comparison to avoid PROJ database issues)
    backbone_crs_str = str(backbone_src.crs) if backbone_src.crs else ""
    ref_crs_str = str(ref_profile["crs"]) if ref_profile["crs"] else ""
    
    crs_match = False
    try:
        if backbone_src.crs is not None and ref_profile["crs"] is not None:
            crs_match = backbone_src.crs == ref_profile["crs"]
    except:
        # Fallback to string comparison
        crs_match = ("3857" in backbone_crs_str and "3857" in ref_crs_str) or \
                   ("pseudo" in backbone_crs_str.lower() and "pseudo" in ref_crs_str.lower())
    
    if (crs_match and
        backbone_src.width == ref_profile["width"] and
        backbone_src.height == ref_profile["height"] and
        np.allclose(backbone_src.transform, ref_profile["transform"], atol=1e-6)):
        log_progress("  Backbone already in correct format, copying...")
        import shutil
        dst_path.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy2(backbone_path, dst_path)
        return True
    
    # Warp backbone
    return warp_raster_to_backbone(backbone_path, dst_path, ref_profile, "backbone")


def main():
    """Main processing function."""
    total_start = time.time()
    log_progress("="*60)
    log_progress("Colombia CRS Fix Preprocessing")
    log_progress("="*60)
    log_progress(f"Source: {READY_ROOT}")
    log_progress(f"Output: {FIXED_CRS_ROOT}")
    
    # Verify environment setup (PROJ_LIB and GDAL_DATA)
    log_progress("\nVerifying environment setup...")
    proj_lib = os.environ.get("PROJ_LIB", "")
    gdal_data = os.environ.get("GDAL_DATA", "")
    conda_prefix = os.environ.get("CONDA_PREFIX", "")
    
    if proj_lib:
        log_progress(f"  PROJ_LIB: {proj_lib} (exists: {os.path.exists(proj_lib)})")
    else:
        log_progress("  WARNING: PROJ_LIB not set. May use system PROJ.")
    
    if gdal_data:
        log_progress(f"  GDAL_DATA: {gdal_data} (exists: {os.path.exists(gdal_data)})")
    else:
        log_progress("  WARNING: GDAL_DATA not set. May use system GDAL.")
    
    if conda_prefix:
        log_progress(f"  CONDA_PREFIX: {conda_prefix}")
        # Check if PROJ_LIB points to conda env
        if proj_lib and conda_prefix in proj_lib:
            log_progress("  ✓ PROJ_LIB points to conda environment")
        elif proj_lib:
            log_progress("  ⚠ PROJ_LIB does not point to conda environment")
    else:
        log_progress("  INFO: CONDA_PREFIX not set (may be using venv or system Python)")
    
    # Test CRS creation early to catch PROJ database issues
    log_progress("\nTesting CRS creation (checking for PROJ database issues)...")
    try:
        test_crs = get_epsg_3857_crs()
        log_progress("  ✓ CRS creation successful")
    except Exception as e:
        log_progress(f"\n  ⚠ CRS creation warning: {e}")
        log_progress("  Script will attempt to continue with fallback methods...")
        if not proj_lib or not os.path.exists(proj_lib):
            log_progress("\n  TROUBLESHOOTING:")
            log_progress("  - Ensure conda environment is activated")
            log_progress("  - Set PROJ_LIB to conda env's share/proj directory")
            log_progress("  - Example: export PROJ_LIB=\"$CONDA_PREFIX/share/proj\"")
    
    # Load backbone template
    backbone_src, ref_profile = load_backbone_template()
    
    # Process backbone first
    process_backbone(backbone_src, ref_profile)
    backbone_src.close()
    
    # Discover all raster files
    catalog = discover_raster_files()
    
    # Process each dataset
    log_progress("\nProcessing datasets...")
    total_processed = 0
    total_failed = 0
    
    for dataset in sorted(catalog.keys()):
        if dataset == "backbone":
            continue  # Already processed
        
        if dataset not in INCLUDE_DATASETS:
            continue
        
        log_progress(f"\n{dataset}:")
        entries = catalog[dataset]
        
        # Process static files (year=None)
        if None in entries:
            for src_path in entries[None]:
                dst_path = FIXED_CRS_ROOT / dataset / src_path.name
                if dst_path.exists():
                    log_progress(f"  Skipping (exists): {src_path.name}")
                    total_processed += 1
                    continue
                
                if warp_raster_to_backbone(src_path, dst_path, ref_profile, dataset):
                    total_processed += 1
                else:
                    total_failed += 1
        
        # Process yearly files
        for year in sorted([y for y in entries.keys() if y is not None]):
            for src_path in entries[year]:
                dst_path = FIXED_CRS_ROOT / dataset / src_path.name
                if dst_path.exists():
                    log_progress(f"  Skipping (exists): {src_path.name}")
                    total_processed += 1
                    continue
                
                if warp_raster_to_backbone(src_path, dst_path, ref_profile, dataset):
                    total_processed += 1
                else:
                    total_failed += 1
    
    # Summary
    total_time = time.time() - total_start
    log_progress("\n" + "="*60)
    log_progress("PREPROCESSING COMPLETE")
    log_progress("="*60)
    log_progress(f"Processed: {total_processed} files")
    if total_failed > 0:
        log_progress(f"Failed: {total_failed} files")
    log_progress(f"Time: {total_time/60:.1f} minutes")
    log_progress(f"\nFixed rasters available at: {FIXED_CRS_ROOT}")
    log_progress("\nNext step: Run colombia_merge (it will automatically use fixed_crs/)")


if __name__ == "__main__":
    main()

