#!/usr/bin/env python3
"""
Embeddings and WDPA Preprocessing
==================================

Objective:
    Reproject and resample yearly embeddings and WDPA rasters to align with
    the backbone reference grid. Ensures all datasets share the same CRS,
    transform, and dimensions for downstream ML processing.

Inputs:
    - Reference: `data/ready/backbone/backbone.tif` (defines target grid)
    - Embeddings: `data/ready/embeddings/embeddings_<year>/SatelliteEmbeddings_SA_1km_<year>_merged.tif` (2018-2024)
    - WDPA: `data/ready/WDPA/WDPA_SA_1km_<year>.tif` (2017-2024)

Outputs:
    - Aligned embeddings: `data/ml/embeddings_aligned/<year>.tif` (float32, bilinear resampling)
    - Aligned WDPA: `data/ml/wdpa_aligned/<year>.tif` (uint8, nearest resampling, nodata=0)

Processing:
    - Embeddings: bilinear resampling, float32 dtype
    - WDPA: nearest resampling, uint8 dtype, nodata=0
    - Strict alignment checks verify CRS, transform, and dimensions match
    - Parallel processing using all available CPU cores
"""

import sys
import logging
from pathlib import Path
from typing import Tuple, Dict, Optional
import time
import multiprocessing
from concurrent.futures import ProcessPoolExecutor, as_completed

import numpy as np
import rasterio
from rasterio.enums import Resampling
from rasterio.vrt import WarpedVRT
from rasterio import windows

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


# Paths
PROJECT_ROOT = Path(__file__).resolve().parents[3]
BACKBONE_PATH = PROJECT_ROOT / "data" / "ready" / "backbone" / "backbone.tif"
EMBEDDINGS_INPUT_DIR = PROJECT_ROOT / "data" / "ready" / "embeddings"
WDPA_INPUT_DIR = PROJECT_ROOT / "data" / "ready" / "WDPA"
EMBEDDINGS_OUTPUT_DIR = PROJECT_ROOT / "data" / "ml" / "embeddings_aligned"
WDPA_OUTPUT_DIR = PROJECT_ROOT / "data" / "ml" / "wdpa_aligned"

EMBEDDINGS_YEARS = list(range(2018, 2025))  # 2018-2024
WDPA_YEARS = list(range(2017, 2025))  # 2017-2024

# Number of parallel workers (use all available CPUs by default)
NUM_WORKERS = multiprocessing.cpu_count()


def load_reference_profile() -> Dict:
    """Load the backbone raster profile as the reference grid."""
    if not BACKBONE_PATH.exists():
        raise FileNotFoundError(
            f"Reference backbone raster not found at {BACKBONE_PATH}. "
            "Run backbone preprocessing first."
        )
    
    with rasterio.open(BACKBONE_PATH) as src:
        profile = src.profile.copy()
    
    logger.info(f"Loaded reference profile from {BACKBONE_PATH.name}")
    logger.info(f"  CRS: {profile['crs']}")
    logger.info(f"  Dimensions: {profile['width']} x {profile['height']}")
    logger.info(f"  Transform: {profile['transform']}")
    
    return profile


def check_alignment(src_path: Path, ref_profile: Dict) -> Tuple[bool, str]:
    """
    Check if a raster is already aligned with the reference grid.
    Returns (is_aligned, reason).
    """
    try:
        with rasterio.open(src_path) as src:
            if src.shape != (ref_profile["height"], ref_profile["width"]):
                return False, f"shape mismatch: {src.shape} vs ({ref_profile['height']}, {ref_profile['width']})"
            
            if src.crs != ref_profile["crs"]:
                return False, f"CRS mismatch: {src.crs} vs {ref_profile['crs']}"
            
            if not np.allclose(src.transform, ref_profile["transform"], atol=1e-6):
                return False, f"transform mismatch: {src.transform} vs {ref_profile['transform']}"
            
            return True, "fully aligned"
    except Exception as e:
        return False, f"error checking alignment: {e}"


def create_output_profile(
    ref_profile: Dict,
    dtype: str,
    count: int,
    nodata,
    block_size: int = 512
) -> Dict:
    """
    Create output profile with explicit GTiff settings including block sizes.
    """
    profile = ref_profile.copy()
    profile.update(
        driver="GTiff",
        dtype=dtype,
        count=count,
        nodata=nodata,
        compress="lzw",
        tiled=True,
        blockxsize=block_size,
        blockysize=block_size,
        BIGTIFF="YES"
    )
    return profile


def reproject_embeddings(
    src_path: Path,
    ref_profile: Dict,
    output_path: Path
) -> None:
    """
    Reproject/resample embeddings raster to reference grid using windowed processing.
    Uses WarpedVRT for reprojection and bilinear resampling with float32 dtype.
    Processes data window-by-window to avoid loading full arrays into memory.
    """
    logger.info(f"Processing embeddings: {src_path.name}")
    start_time = time.time()
    
    output_path.parent.mkdir(parents=True, exist_ok=True)
    block_size = 512  # Standard block size for windowed processing
    
    # Check alignment
    is_aligned, reason = check_alignment(src_path, ref_profile)
    
    with rasterio.open(src_path) as src:
        count = src.count
        dst_height = ref_profile["height"]
        dst_width = ref_profile["width"]
        
        # Create output profile
        output_profile = create_output_profile(
            ref_profile, "float32", count, np.nan, block_size
        )
        
        # Handle source nodata conversion
        src_nodata = src.nodata if src.nodata is not None else None
        
        if is_aligned:
            logger.info(f"  Already aligned ({reason}), copying with dtype conversion (windowed)...")
            # Windowed copy with dtype conversion
            with rasterio.open(output_path, "w", **output_profile) as dst:
                # Process in blocks
                for _, window in dst.block_windows(1):
                    # Read window from source
                    src_window_data = src.read(window=window, masked=False).astype(np.float32)
                    
                    # Handle nodata conversion
                    if src_nodata is not None:
                        src_window_data[src_window_data == src_nodata] = np.nan
                    
                    # Write all bands at once
                    dst.write(src_window_data, window=window)
        else:
            logger.info(f"  Not aligned ({reason}), reprojecting with bilinear resampling (windowed)...")
            
            # Use WarpedVRT for virtual reprojection
            with WarpedVRT(
                src,
                src_crs=src.crs,
                src_transform=src.transform,
                src_nodata=src_nodata,
                dst_crs=ref_profile["crs"],
                dst_transform=ref_profile["transform"],
                dst_width=dst_width,
                dst_height=dst_height,
                resampling=Resampling.bilinear,
                dtype="float32",
                nodata=np.nan,
            ) as vrt:
                # Write output window-by-window
                with rasterio.open(output_path, "w", **output_profile) as dst:
                    # Process window-by-window (all bands at once)
                    for _, window in dst.block_windows(1):
                        # Read all bands from VRT (already reprojected)
                        window_data = vrt.read(window=window, masked=False).astype(np.float32)
                        # Write all bands at once
                        dst.write(window_data, window=window)
    
    # Verify alignment
    is_aligned_after, reason_after = check_alignment(output_path, ref_profile)
    if not is_aligned_after:
        raise RuntimeError(f"Alignment check failed after reprojection: {reason_after}")
    
    logger.info(f"  Completed in {time.time() - start_time:.1f}s")


def reproject_wdpa(
    src_path: Path,
    ref_profile: Dict,
    output_path: Path
) -> None:
    """
    Reproject/resample WDPA raster to reference grid using windowed processing.
    Uses nearest resampling, uint8 dtype, nodata=0.
    Processes data window-by-window to avoid loading full arrays into memory.
    """
    logger.info(f"Processing WDPA: {src_path.name}")
    start_time = time.time()
    
    output_path.parent.mkdir(parents=True, exist_ok=True)
    block_size = 512  # Standard block size for windowed processing
    
    # Check alignment
    is_aligned, reason = check_alignment(src_path, ref_profile)
    
    with rasterio.open(src_path) as src:
        dst_height = ref_profile["height"]
        dst_width = ref_profile["width"]
        src_nodata = src.nodata if src.nodata is not None else 0
        
        # Create output profile
        output_profile = create_output_profile(
            ref_profile, "uint8", 1, 0, block_size
        )
        
        if is_aligned:
            logger.info(f"  Already aligned ({reason}), copying with dtype conversion (windowed)...")
            # Windowed copy with dtype conversion
            with rasterio.open(output_path, "w", **output_profile) as dst:
                for _, window in dst.block_windows(1):
                    # Read window from source
                    window_data = src.read(1, window=window, masked=False)
                    
                    # Convert nodata to 0
                    if src_nodata is not None and src_nodata != 0:
                        window_data = np.where(window_data == src_nodata, 0, window_data)
                    
                    # Clip to valid uint8 range and convert
                    window_data = np.clip(window_data, 0, 255).astype(np.uint8)
                    
                    # Write to output
                    dst.write(window_data, 1, window=window)
        else:
            logger.info(f"  Not aligned ({reason}), reprojecting with nearest resampling (windowed)...")
            
            # Use WarpedVRT for virtual reprojection
            with WarpedVRT(
                src,
                src_crs=src.crs,
                src_transform=src.transform,
                src_nodata=src_nodata,
                dst_crs=ref_profile["crs"],
                dst_transform=ref_profile["transform"],
                dst_width=dst_width,
                dst_height=dst_height,
                resampling=Resampling.nearest,
                dtype="uint8",
                nodata=0,
            ) as vrt:
                # Write output window-by-window
                with rasterio.open(output_path, "w", **output_profile) as dst:
                    for _, window in dst.block_windows(1):
                        # Read from VRT (already reprojected, nodata=0 handled by VRT)
                        window_data = vrt.read(1, window=window, masked=False).astype(np.uint8)
                        
                        # Ensure values are in valid range
                        window_data = np.clip(window_data, 0, 255)
                        
                        # Write to output
                        dst.write(window_data, 1, window=window)
    
    # Verify alignment
    is_aligned_after, reason_after = check_alignment(output_path, ref_profile)
    if not is_aligned_after:
        raise RuntimeError(f"Alignment check failed after reprojection: {reason_after}")
    
    # Verify nodata
    with rasterio.open(output_path) as dst_check:
        if dst_check.nodata != 0:
            raise RuntimeError(f"WDPA output nodata is {dst_check.nodata}, expected 0")
    
    logger.info(f"  Completed in {time.time() - start_time:.1f}s")


def verify_output(output_path: Path, ref_profile: Dict, expected_dtype: str) -> None:
    """Verify output raster matches reference profile and expected dtype."""
    if not output_path.exists():
        raise FileNotFoundError(f"Output file not created: {output_path}")
    
    with rasterio.open(output_path) as dst:
        # Check dtype of first band (all bands should have same dtype)
        actual_dtype = str(dst.dtypes[0])
        if actual_dtype != expected_dtype:
            raise ValueError(
                f"Output dtype mismatch: {actual_dtype} != {expected_dtype} "
                f"for {output_path.name}"
            )
        
        is_aligned, reason = check_alignment(output_path, ref_profile)
        if not is_aligned:
            raise RuntimeError(
                f"Output alignment verification failed: {reason} "
                f"for {output_path.name}"
            )
    
    logger.info(f"  ✓ Verified: {output_path.name}")


def process_embeddings_year(args: Tuple[int, Dict, Path, Path, Path]) -> Tuple[int, bool, Optional[str]]:
    """
    Worker function to process embeddings for a single year.
    Returns (year, success, error_message).
    """
    year, ref_profile, embeddings_input_dir, embeddings_output_dir, project_root = args
    
    # Re-initialize paths (they need to be picklable)
    # Files are now in year-specific subdirectories: embeddings_{year}/
    embeddings_input = embeddings_input_dir / f"embeddings_{year}" / f"SatelliteEmbeddings_SA_1km_{year}_merged.tif"
    embeddings_output = embeddings_output_dir / f"{year}.tif"
    
    if not embeddings_input.exists():
        return (year, False, f"Embeddings input not found: {embeddings_input.name}")
    
    try:
        reproject_embeddings(embeddings_input, ref_profile, embeddings_output)
        verify_output(embeddings_output, ref_profile, "float32")
        return (year, True, None)
    except Exception as e:
        return (year, False, str(e))


def process_wdpa_year(args: Tuple[int, Dict, Path, Path, Path]) -> Tuple[int, bool, Optional[str]]:
    """
    Worker function to process WDPA for a single year.
    Returns (year, success, error_message).
    """
    year, ref_profile, wdpa_input_dir, wdpa_output_dir, project_root = args
    
    # Re-initialize paths (they need to be picklable)
    wdpa_input = wdpa_input_dir / f"WDPA_SA_1km_{year}.tif"
    wdpa_output = wdpa_output_dir / f"{year}.tif"
    
    if not wdpa_input.exists():
        return (year, False, f"WDPA input not found: {wdpa_input.name}")
    
    try:
        reproject_wdpa(wdpa_input, ref_profile, wdpa_output)
        verify_output(wdpa_output, ref_profile, "uint8")
        return (year, True, None)
    except Exception as e:
        return (year, False, str(e))


def main() -> int:
    """Main processing function."""
    logger.info("=" * 70)
    logger.info("Embeddings and WDPA Preprocessing")
    logger.info("=" * 70)
    
    # Load reference profile
    try:
        ref_profile = load_reference_profile()
    except FileNotFoundError as e:
        logger.error(str(e))
        return 1
    
    logger.info(f"Using {NUM_WORKERS} parallel workers")
    logger.info("")
    
    # Process embeddings for 2018-2024 in parallel
    logger.info("")
    logger.info(f"Processing embeddings for {len(EMBEDDINGS_YEARS)} years using {NUM_WORKERS} workers...")
    logger.info("-" * 70)
    
    processed_embeddings = []
    failed = []
    
    embeddings_args = [
        (year, ref_profile, EMBEDDINGS_INPUT_DIR, EMBEDDINGS_OUTPUT_DIR, PROJECT_ROOT)
        for year in EMBEDDINGS_YEARS
    ]
    
    with ProcessPoolExecutor(max_workers=NUM_WORKERS) as executor:
        future_to_year = {
            executor.submit(process_embeddings_year, args): args[0]
            for args in embeddings_args
        }
        
        for future in as_completed(future_to_year):
            year = future_to_year[future]
            try:
                year_result, success, error_msg = future.result()
                if success:
                    logger.info(f"  ✓ Completed embeddings for {year_result}")
                    processed_embeddings.append(year_result)
                else:
                    logger.error(f"  ✗ Failed embeddings for {year_result}: {error_msg}")
                    failed.append(f"embeddings_{year_result}")
            except Exception as e:
                logger.error(f"  ✗ Exception processing embeddings for {year}: {e}")
                failed.append(f"embeddings_{year}")
    
    # Process WDPA for 2017-2024 in parallel
    logger.info("")
    logger.info(f"Processing WDPA for {len(WDPA_YEARS)} years using {NUM_WORKERS} workers...")
    logger.info("-" * 70)
    
    processed_wdpa = []
    
    wdpa_args = [
        (year, ref_profile, WDPA_INPUT_DIR, WDPA_OUTPUT_DIR, PROJECT_ROOT)
        for year in WDPA_YEARS
    ]
    
    with ProcessPoolExecutor(max_workers=NUM_WORKERS) as executor:
        future_to_year = {
            executor.submit(process_wdpa_year, args): args[0]
            for args in wdpa_args
        }
        
        for future in as_completed(future_to_year):
            year = future_to_year[future]
            try:
                year_result, success, error_msg = future.result()
                if success:
                    logger.info(f"  ✓ Completed WDPA for {year_result}")
                    processed_wdpa.append(year_result)
                else:
                    logger.error(f"  ✗ Failed WDPA for {year_result}: {error_msg}")
                    failed.append(f"wdpa_{year_result}")
            except Exception as e:
                logger.error(f"  ✗ Exception processing WDPA for {year}: {e}")
                failed.append(f"wdpa_{year}")
    
    # Summary
    logger.info("")
    logger.info("=" * 70)
    logger.info("Processing Summary")
    logger.info("=" * 70)
    logger.info(f"Successfully processed embeddings: {len(processed_embeddings)} years")
    logger.info(f"  Years: {processed_embeddings}")
    logger.info(f"Successfully processed WDPA: {len(processed_wdpa)} years")
    logger.info(f"  Years: {processed_wdpa}")
    
    if failed:
        logger.warning(f"Failed or missing: {len(failed)} files")
        logger.warning(f"  Files: {failed}")
        return 1
    
    logger.info("All files processed successfully!")
    return 0


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        logger.info("Interrupted by user")
        sys.exit(1)
    except Exception as e:
        logger.exception(f"Unexpected error: {e}")
        sys.exit(1)

