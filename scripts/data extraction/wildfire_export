"""
Dataset: MODIS/061/MCD64A1 Burned Area Monthly Collection.
Temporal coverage: Annual aggregates for South America from 2000 through 2024.
Overview: Authenticates with Google Earth Engine, aggregates annual burned area indicators, and exports 1 km GeoTIFFs to Google Drive.
Resampling & reprojection: Burned area scenes are bilinearly resampled and reprojected to EPSG:3857 at 1,000 m before annual summation.
Outputs: One float32 GeoTIFF per year (2000-2024) containing summed burn dates and a binary burned mask clipped to South America.
Usage: export EE_PROJECT_ID=<your-project-id> && python "scripts/data extraction/wildfire_export".
"""

import os

import ee

PROJECT_ID = os.environ.get("EE_PROJECT_ID")


def initialize_earth_engine(project_id=None) -> None:
    """Authenticate and initialize Earth Engine with an optional project."""
    try:
        if project_id:
            ee.Initialize(project=project_id)
        else:
            ee.Initialize()
        print("Earth Engine initialized.")
    except Exception as exc:
        print(f"Initialization failed: {exc}")
        print("Attempting interactive authentication...")
        ee.Authenticate()
        if project_id:
            ee.Initialize(project=project_id)
        else:
            ee.Initialize()
        print("Earth Engine initialized after authentication.")


initialize_earth_engine(PROJECT_ID)

# ----------------------------
# 1) Study area (South America)
# ----------------------------
countries = ee.FeatureCollection('USDOS/LSIB_SIMPLE/2017')
region_fc = countries.filter(ee.Filter.inList('wld_rgn', ['South America']))
region = region_fc.geometry()
export_region = region.bounds()

# ----------------------------
# 2) Settings
# ----------------------------
CRS = 'EPSG:3857'
KM = 1000
# MODIS Burned Area dataset
BURNED_AREA = ee.ImageCollection('MODIS/061/MCD64A1')
# Burn Date band contains Julian day of burn (1-366), with 0 for no burn
BURN_BAND = 'BurnDate'

def rename_burn_band(img: ee.Image, prefix: str) -> ee.Image:
    """Rename burn date band with a prefix."""
    return img.select(BURN_BAND).rename(f"{prefix}_burn_date")

# ----------------------------
# 3) Process burned area data per year
# ----------------------------
def process_burned_area_year(start: str, end: str, prefix: str) -> ee.Image:
    # Filter to window + AOI + burn date band
    coll = (
        BURNED_AREA.filterDate(start, end)
                   .filterBounds(region)
                   .select(BURN_BAND)
                   .map(lambda img: (
                       img
                         .resample('bilinear')                         # bilinear resampling
                         .reproject(crs=CRS, scale=KM)                 # force 1 km @ EPSG:3857
                   ))
    )
    
    # For burned area, we want to sum the burn dates across the year
    # This gives us total burned area for the year (non-zero pixels indicate burns)
    # We'll also create a binary mask for burned vs unburned
    burn_date_sum = ee.ImageCollection(coll).sum().clip(region).unmask(0).toFloat()
    
    # Create binary burned area mask (1 if burned anywhere in year, 0 otherwise)
    burned_mask = burn_date_sum.gt(0).clip(region).unmask(0).toFloat()
    
    # Create composite with both burn date sum and binary mask
    composite = burn_date_sum.addBands(burned_mask).rename([f"{prefix}_burn_date", f"{prefix}_burned_mask"])
    
    return composite

# ----------------------------
# 4) Process data for years 2000-2024
# ----------------------------
years = list(range(2000, 2025))  # 2000 to 2024 inclusive
images = {}

for year in years:
    start_date = f'{year}-01-01'
    end_date = f'{year+1}-01-01'
    prefix = f'burned_area_{year}'
    
    print(f'Processing year {year}...')
    images[year] = process_burned_area_year(start_date, end_date, prefix)

# (Optional) sanity print for first year
print('Bands:', images[2000].bandNames().getInfo())

# ----------------------------
# 5) Export to Google Drive for all years
# ----------------------------
tasks = []
for year in years:
    task = ee.batch.Export.image.toDrive(
        image=images[year],
        description=f'Burned_Area_SA_1km_{year}',
        folder='GEE_exports',                 # change or remove as you like
        fileNamePrefix=f'Burned_Area_SA_1km_{year}',
        region=export_region,
        crs=CRS,
        scale=KM,
        maxPixels=1e13
    )
    task.start()
    tasks.append(task)
    print(f'Export started for {year}:', task.id)

# ----------------------------
# (Optional) Export to Cloud Storage instead of Drive
# ----------------------------
# tasks_gcs = []
# for year in years:
#     task_gcs = ee.batch.Export.image.toCloudStorage(
#         image=images[year],
#         description=f'Burned_Area_SA_1km_{year}_gcs',
#         bucket='your-gcs-bucket',
#         fileNamePrefix=f'gee/Burned_Area_SA_1km_{year}',
#         region=export_region,
#         crs=CRS,
#         scale=KM,
#         maxPixels=1e13
#     )
#     task_gcs.start()
#     tasks_gcs.append(task_gcs)
#     print(f'GCS export started for {year}:', task_gcs.id)

print(f"\nStarted {len(tasks)} export tasks for burned area data (2000-2024).")
print("Each export contains 2 bands:")
print("   - burn_date: Sum of Julian burn days (0 = no burn, >0 = burned)")
print("   - burned_mask: Binary mask (1 = burned anywhere in year, 0 = never burned)")
print("Check your Google Drive 'GEE_exports' folder for results.")
