#!/usr/bin/env python3

"""Temporal Transition Sampling Script

Purpose: Build a balanced dataset for predicting new WDPA establishment.
Input:  merged_panel_2000_2024.parquet
Process: Create lagged WDPA column, identify 0‚Üí1 transitions, sample ~2M rows.
Output: sample_training.parquet
"""

from __future__ import annotations

import os
import sys
import time
from pathlib import Path

import duckdb
import wandb


# Configuration
TOTAL_SAMPLE_SIZE = 2_000_000
POSITIVE_LIMIT = 1_000_000
RANDOM_STATE = 42


def main() -> None:
    start_time = time.time()
    
    # Get W&B credentials from environment
    wandb_api_key = os.environ.get("WANDB_API_KEY")
    wandb_entity = os.environ.get("WANDB_ENTITY")
    
    if not wandb_api_key:
        print("‚ö†Ô∏è  Warning: WANDB_API_KEY not found in environment")
    if not wandb_entity:
        print("‚ö†Ô∏è  Warning: WANDB_ENTITY not found in environment")
    
    # Initialize W&B
    print("üîÑ Initializing Weights & Biases...")
    wandb.init(
        project="ml-training-preprocessing",
        entity=wandb_entity,
        name=f"sample_preprocessing_{time.strftime('%Y%m%d_%H%M%S')}",
        config={
            "total_sample_size": TOTAL_SAMPLE_SIZE,
            "positive_limit": POSITIVE_LIMIT,
            "random_state": RANDOM_STATE,
        },
    )
    print("‚úÖ W&B connected")
    
    # Setup paths (outside try block for cleanup in finally)
    repo_root = Path(__file__).resolve().parents[3]
    input_path = repo_root / "data/ml/merged_panel_2000_2024.parquet"
    output_path = repo_root / "data/ml/sample_training.parquet"
    temp_dir = repo_root / "data/ml/temp"
    temp_transitions = temp_dir / "temp_transitions.parquet"
    
    try:
        
        temp_dir.mkdir(parents=True, exist_ok=True)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        print(f"\nüìÇ Input: {input_path}")
        print(f"üìÇ Output: {output_path}")
        
        if not input_path.exists():
            raise FileNotFoundError(f"Input file not found: {input_path}")
        
        # Initialize DuckDB with memory-efficient settings
        con = duckdb.connect()
        num_threads = 8 if os.environ.get("SCRATCH") else 4
        con.execute(f"SET threads={num_threads}")
        con.execute("SET preserve_insertion_order=false")
        con.execute("SET memory_limit='80GB'")  # Leave headroom on 128GB system
        
        # Use SCRATCH temp directory if on Euler
        temp_dir_env = os.environ.get("SCRATCH") or str(temp_dir)
        con.execute(f"SET temp_directory='{temp_dir_env}/duckdb_temp'")
        con.execute("PRAGMA max_temp_directory_size='100GB'")
        
        print(f"‚öôÔ∏è  DuckDB configured: {num_threads} threads, memory_limit=80GB")
        
        wandb.log({"config/threads": num_threads, "config/memory_limit_gb": 80})
        
        # Escape paths for SQL
        escaped_in = str(input_path).replace("'", "''")
        escaped_out = str(output_path).replace("'", "''")
        escaped_temp = str(temp_transitions).replace("'", "''")
        
        # Step 1: Create lagged WDPA using memory-efficient self-join
        print("\nüîÑ Step 1: Computing lagged WDPA and transitions (self-join)...")
        print("   Using self-join instead of window functions for memory efficiency")
        step1_start = time.time()
        
        # Self-join approach: much more memory-efficient than LAG()
        transition_query = f"""
        SELECT 
            curr.*,
            COALESCE(prev.WDPA_b1, 0) AS WDPA_prev,
            CASE 
                WHEN COALESCE(prev.WDPA_b1, 0) = 0 AND COALESCE(curr.WDPA_b1, 0) = 1 THEN 1
                ELSE 0
            END AS transition_01
        FROM read_parquet('{escaped_in}') AS curr
        LEFT JOIN read_parquet('{escaped_in}') AS prev
            ON curr.row = prev.row 
            AND curr.col = prev.col 
            AND prev.year = curr.year - 1
        WHERE prev.year IS NOT NULL
        """
        
        # Materialize to temporary file to avoid memory overflow
        print(f"   Materializing to temporary file: {temp_transitions}")
        con.execute(f"""
            COPY ({transition_query})
            TO '{escaped_temp}'
            (FORMAT PARQUET, COMPRESSION ZSTD)
        """)
        
        step1_time = time.time() - step1_start
        print(f"   ‚úÖ Completed in {step1_time:.1f}s ({step1_time/60:.1f} min)")
        wandb.log({"timing/step1_seconds": step1_time, "timing/step1_minutes": step1_time/60})
        
        # Step 2: Count positives and negatives from temporary file
        print("\nüîÑ Step 2: Counting transitions...")
        step2_start = time.time()
        
        counts = con.execute(f"""
            SELECT 
                SUM(transition_01) AS positives,
                SUM(CASE WHEN transition_01 = 0 THEN 1 ELSE 0 END) AS negatives,
                COUNT(*) AS total,
                MIN(year) AS year_min,
                MAX(year) AS year_max
            FROM read_parquet('{escaped_temp}')
        """).fetchone()
        
        positives, negatives, total, year_min, year_max = counts
        
        print(f"   Total rows (with lagged data): {total:,}")
        print(f"   Positive transitions (0‚Üí1):    {positives:,}")
        print(f"   Negative transitions:          {negatives:,}")
        print(f"   Year range:                    {year_min}‚Äì{year_max}")
        
        step2_time = time.time() - step2_start
        wandb.log({
            "data/total_rows": total,
            "data/positives": positives,
            "data/negatives": negatives,
            "data/positive_ratio": positives / total if total > 0 else 0,
            "data/year_min": year_min,
            "data/year_max": year_max,
            "timing/step2_seconds": step2_time,
        })
        
        if positives == 0:
            raise ValueError("No positive transitions found! Cannot build training sample.")
        
        # Step 3: Determine sampling strategy
        print("\nüîÑ Step 3: Determining sampling strategy...")
        
        sample_positives = min(POSITIVE_LIMIT, positives)
        sample_negatives = min(sample_positives, negatives)  # Match positives for balance
        total_sample = sample_positives + sample_negatives
        
        print(f"   Sampling {sample_positives:,} positives (of {positives:,} available)")
        print(f"   Sampling {sample_negatives:,} negatives (of {negatives:,} available)")
        print(f"   Total sample size: {total_sample:,}")
        print(f"   Class balance: {sample_positives/total_sample*100:.1f}% positive")
        
        wandb.log({
            "sampling/positives": sample_positives,
            "sampling/negatives": sample_negatives,
            "sampling/total": total_sample,
            "sampling/balance": sample_positives / total_sample if total_sample > 0 else 0,
        })
        
        # Step 4: Sample and write output (separate sampling for each class)
        print("\nüîÑ Step 4: Sampling and writing output...")
        step4_start = time.time()
        
        # Create temporary files for each class
        temp_positives = temp_dir / "temp_positives.parquet"
        temp_negatives = temp_dir / "temp_negatives.parquet"
        escaped_pos = str(temp_positives).replace("'", "''")
        escaped_neg = str(temp_negatives).replace("'", "''")
        
        # Sample positives first
        print(f"   Sampling {sample_positives:,} positive transitions...")
        con.execute(f"""
            COPY (
                SELECT *
                FROM (
                    SELECT *
                    FROM read_parquet('{escaped_temp}')
                    WHERE transition_01 = 1
                )
                USING SAMPLE reservoir({sample_positives} ROWS) REPEATABLE ({RANDOM_STATE})
            )
            TO '{escaped_pos}'
            (FORMAT PARQUET, COMPRESSION ZSTD)
        """)
        
        # Sample negatives
        print(f"   Sampling {sample_negatives:,} negative transitions...")
        con.execute(f"""
            COPY (
                SELECT *
                FROM (
                    SELECT *
                    FROM read_parquet('{escaped_temp}')
                    WHERE transition_01 = 0
                )
                USING SAMPLE reservoir({sample_negatives} ROWS) REPEATABLE ({RANDOM_STATE})
            )
            TO '{escaped_neg}'
            (FORMAT PARQUET, COMPRESSION ZSTD)
        """)
        
        # Combine both samples into final output
        print(f"   Combining samples into final output...")
        con.execute(f"""
            COPY (
                SELECT * FROM read_parquet('{escaped_pos}')
                UNION ALL
                SELECT * FROM read_parquet('{escaped_neg}')
            )
            TO '{escaped_out}'
            (FORMAT PARQUET, COMPRESSION ZSTD)
        """)
        
        step4_time = time.time() - step4_start
        print(f"   ‚úÖ Written to {output_path} in {step4_time:.1f}s")
        wandb.log({"timing/step4_seconds": step4_time})
        
        # Clean up temporary files
        print("   üßπ Cleaning up temporary files...")
        temp_transitions.unlink(missing_ok=True)
        temp_positives.unlink(missing_ok=True)
        temp_negatives.unlink(missing_ok=True)
        print("   ‚úÖ Temporary files removed")
        
        # Step 5: Verify output
        print("\nüîÑ Step 5: Verifying output...")
        
        verify_counts = con.execute(f"""
            SELECT 
                SUM(transition_01) AS pos_written,
                SUM(CASE WHEN transition_01 = 0 THEN 1 ELSE 0 END) AS neg_written,
                COUNT(*) AS total_written,
                COUNT(DISTINCT year) AS n_years,
                MIN(year) AS min_year,
                MAX(year) AS max_year
            FROM read_parquet('{escaped_out}')
        """).fetchone()
        
        pos_written, neg_written, total_written, n_years, min_year, max_year = verify_counts
        file_size_mb = output_path.stat().st_size / (1024 * 1024)
        total_time = time.time() - start_time
        
        # Print summary
        print("\n" + "="*70)
        print("‚úÖ SAMPLING COMPLETE")
        print("="*70)
        print(f"  Total rows:       {total_written:,}")
        print(f"  Positives (0‚Üí1):  {pos_written:,} ({pos_written/total_written*100:.1f}%)")
        print(f"  Negatives:        {neg_written:,} ({neg_written/total_written*100:.1f}%)")
        print(f"  Years covered:    {n_years} years ({min_year}‚Äì{max_year})")
        print(f"  File size:        {file_size_mb:.1f} MB")
        print(f"  Total time:       {total_time:.1f}s ({total_time/60:.1f} min)")
        print("="*70)
        
        # Log final results to W&B
        wandb.log({
            "output/total_rows": total_written,
            "output/positives": pos_written,
            "output/negatives": neg_written,
            "output/balance": pos_written / total_written if total_written > 0 else 0,
            "output/n_years": n_years,
            "output/year_min": min_year,
            "output/year_max": max_year,
            "output/file_size_mb": file_size_mb,
            "timing/total_seconds": total_time,
            "timing/total_minutes": total_time / 60,
            "status": "success",
        })
        
        # Warn if imbalanced
        balance = pos_written / total_written if total_written > 0 else 0
        if balance < 0.4 or balance > 0.6:
            print(f"\n‚ö†Ô∏è  Warning: Class balance is {balance*100:.1f}% (target: 50%)")
            wandb.alert(
                title="Class Imbalance Detected",
                text=f"Class balance is {balance*100:.1f}% positive",
                level=wandb.AlertLevel.WARN
            )
        
        print("\n‚úÖ All done!")
        
    except Exception as e:
        error_msg = f"{type(e).__name__}: {str(e)}"
        print(f"\n‚ùå ERROR: {error_msg}")
        wandb.log({
            "status": "failed",
            "error_type": type(e).__name__,
            "error_message": str(e),
        })
        raise
    
    finally:
        # Clean up temporary files in case of error
        try:
            cleanup_files = [
                temp_transitions,
                temp_dir / "temp_positives.parquet",
                temp_dir / "temp_negatives.parquet"
            ]
            cleaned = False
            for f in cleanup_files:
                if f.exists():
                    f.unlink()
                    cleaned = True
            if cleaned:
                print("üßπ Cleaned up temporary files")
        except:
            pass
        
        wandb.finish()
        print("üèÅ W&B run finished")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\n‚ùå Script failed: {e}", file=sys.stderr)
        sys.exit(1)
