#!/usr/bin/env python3

"""
Sampling script for model1 training/test splits.

Rules
-----
TRAIN (2000–2017):
  - Keep all positives (transition_01 = 1)
  - Sample negatives at 1:20 ratio, stratified by year

TEST (2018–2024):
  - Keep full risk set (no sampling)
"""

from __future__ import annotations

import os
import sys
import time
from pathlib import Path

import duckdb
import wandb

# Configuration
RANDOM_STATE = 42
TRAIN_YEARS = (2000, 2017)
TEST_YEARS = (2018, 2024)
WANDB_PROJECT = "ml-training-preprocessing"


def resolve_input() -> Path:
    """Locate merged_panel_final.parquet (prefer $SCRATCH if present)."""
    repo_root = Path(__file__).resolve().parents[3]
    scratch_root = Path(os.environ["SCRATCH"]) if os.environ.get("SCRATCH") else None

    candidates = []
    if scratch_root is not None:
        candidates.append(scratch_root / "data/ml/merged_panel_final.parquet")
    candidates.append(repo_root / "data/ml/merged_panel_final.parquet")

    for cand in candidates:
        if cand.exists():
            return cand

    raise FileNotFoundError("merged_panel_final.parquet not found in expected locations")


def configure_duckdb(con: duckdb.DuckDBPyConnection) -> None:
    """Apply sensible local/Euler defaults."""
    is_euler = bool(os.environ.get("SCRATCH"))
    slurm_cpus = int(os.environ.get("SLURM_CPUS_PER_TASK", "0"))
    num_threads = slurm_cpus if slurm_cpus > 0 else (48 if is_euler else 4)

    # Match DuckDB memory to Slurm allocation when present
    slurm_mem_per_cpu_mb = os.environ.get("SLURM_MEM_PER_CPU")
    if slurm_mem_per_cpu_mb and slurm_cpus:
        total_mem_mb = int(slurm_mem_per_cpu_mb) * slurm_cpus
        memory_limit_gb = max(1, total_mem_mb // 1024)
    else:
        memory_limit_gb = 128 if is_euler else 16

    con.execute(f"SET threads={num_threads}")
    con.execute("SET preserve_insertion_order=false")
    con.execute(f"SET memory_limit='{memory_limit_gb}GB'")

    temp_dir = os.environ.get("SCRATCH") or (Path(__file__).parent / "temp")
    temp_dir_sql = str(temp_dir).replace("'", "''")
    con.execute(f"SET temp_directory='{temp_dir_sql}/duckdb_temp'")

    if is_euler:
        con.execute("PRAGMA max_temp_directory_size='200GB'")

    print(f"DuckDB configured: {num_threads} threads, {memory_limit_gb}GB memory")
    print(f"Running on: {'Euler cluster' if is_euler else 'local machine'}")


def log_year_counts(con: duckdb.DuckDBPyConnection, parquet_path: Path, label: str, use_wandb: bool = False) -> None:
    escaped = str(parquet_path).replace("'", "''")
    rows = con.execute(
        f"""
        SELECT
            year,
            SUM(transition_01) AS positives,
            SUM(CASE WHEN transition_01 = 0 THEN 1 ELSE 0 END) AS negatives,
            COUNT(*) AS total,
            CASE WHEN COUNT(*) > 0 THEN SUM(transition_01)::DOUBLE / COUNT(*) ELSE 0 END AS pos_ratio
        FROM read_parquet('{escaped}')
        GROUP BY year
        ORDER BY year
        """
    ).fetchall()

    print(f"\n{label} per-year counts:")
    for year, pos, neg, total, ratio in rows:
        print(f"  {year}: total={total:,} pos={pos:,} neg={neg:,} pos_ratio={ratio:.5f}")

    if use_wandb:
        wandb.log({f"{label.lower().replace(' ', '_')}/per_year": [dict(year=y, positives=p, negatives=n, total=t, pos_ratio=r) for y, p, n, t, r in rows]})


def main() -> None:
    start_time = time.time()

    wandb_api_key = os.environ.get("WANDB_API_KEY")
    wandb_entity = os.environ.get("WANDB_ENTITY")
    use_wandb = bool(wandb_api_key and wandb_entity)
    
    if use_wandb:
        print("Initializing Weights & Biases...")
        wandb.init(
            project=WANDB_PROJECT,
            entity=wandb_entity,
            name=f"model1_preprocessing_{time.strftime('%Y%m%d_%H%M%S')}",
            config={
                "random_state": RANDOM_STATE,
                "train_years": TRAIN_YEARS,
                "test_years": TEST_YEARS,
                "sampling_ratio_neg_per_pos": 20,
            },
        )
        print("W&B connected\n")
    else:
        print("W&B not configured (WANDB_API_KEY or WANDB_ENTITY not set)\n")

    input_path = resolve_input()
    base_dir = input_path.parent
    train_out = base_dir / "train.parquet"
    test_out = base_dir / "test.parquet"

    print(f"\nInput: {input_path}")
    print(f"Train output: {train_out}")
    print(f"Test output: {test_out}")

    con = duckdb.connect()
    configure_duckdb(con)

    escaped_in = str(input_path).replace("'", "''")
    escaped_train = str(train_out).replace("'", "''")
    escaped_test = str(test_out).replace("'", "''")

    try:
        # TRAIN: positives + 20x negatives per year
        train_sql = f"""
        COPY (
            WITH base AS (
                SELECT * FROM read_parquet('{escaped_in}')
                WHERE year BETWEEN {TRAIN_YEARS[0]} AND {TRAIN_YEARS[1]}
            ),
            year_counts AS (
                SELECT
                    year,
                    SUM(transition_01) AS pos_count,
                    SUM(CASE WHEN transition_01 = 0 THEN 1 ELSE 0 END) AS neg_count
                FROM base
                GROUP BY year
            ),
            positives AS (
                SELECT * FROM base WHERE transition_01 = 1
            ),
            sampled_negs AS (
                SELECT b.*
                FROM base b
                LEFT JOIN year_counts yc ON b.year = yc.year
                WHERE
                    b.transition_01 = 0
                    AND random() < LEAST(1.0, 20 * COALESCE(yc.pos_count, 0)::DOUBLE / NULLIF(COALESCE(yc.neg_count, 0), 0))
            )
            SELECT * FROM positives
            UNION ALL
            SELECT * FROM sampled_negs
        )
        TO '{escaped_train}' (FORMAT PARQUET, COMPRESSION ZSTD)
        """

        print("\nCreating TRAIN split (2000–2017) with 1:20 stratified negatives...")
        # Set random seed for reproducible sampling (normalize integer seed to 0-1 range)
        seed_value = RANDOM_STATE / 100.0
        con.execute(f"SELECT setseed({seed_value})")
        train_start = time.time()
        con.execute(train_sql)
        print(f"TRAIN written in {time.time() - train_start:.1f}s")

        # TEST: full risk set 2018–2024
        test_sql = f"""
        COPY (
            SELECT * FROM read_parquet('{escaped_in}')
            WHERE year BETWEEN {TEST_YEARS[0]} AND {TEST_YEARS[1]}
        )
        TO '{escaped_test}' (FORMAT PARQUET, COMPRESSION ZSTD)
        """

        print("\nCreating TEST split (2018–2024, full risk set)...")
        test_start = time.time()
        con.execute(test_sql)
        print(f"TEST written in {time.time() - test_start:.1f}s")

        # Log counts
        log_year_counts(con, train_out, "TRAIN", use_wandb)
        log_year_counts(con, test_out, "TEST", use_wandb)

        total_train = con.execute(
            f"SELECT COUNT(*) FROM read_parquet('{escaped_train}')"
        ).fetchone()[0]
        total_test = con.execute(
            f"SELECT COUNT(*) FROM read_parquet('{escaped_test}')"
        ).fetchone()[0]

        if use_wandb:
            wandb.log(
                {
                    "train/rows": total_train,
                    "test/rows": total_test,
                    "timing/total_seconds": time.time() - start_time,
                }
            )

        print("\nDone.")

    except Exception as e:
        error_msg = f"{type(e).__name__}: {e}"
        print(f"\nERROR: {error_msg}")
        if use_wandb:
            wandb.log({"status": "failed", "error": error_msg})
        raise
    finally:
        if use_wandb:
            wandb.finish()


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\nScript failed: {e}", file=sys.stderr)
        sys.exit(1)
