#!/usr/bin/env python3
"""
Panel dataset diagnostic visualizations & Data Integrity Debugger.

Added Features:
- Temporal Feature Comparison: Subplots comparing geography of 2011 vs 2013 vs 2015.
- Robust Data Integrity Scan: Automated detection of row-count crashes.
"""

import os
import socket
import getpass
import warnings
from datetime import datetime
from pathlib import Path
from typing import Optional, List

import duckdb
import matplotlib
matplotlib.use("Agg")  # Headless-safe
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

try:
    import wandb
except ImportError:
    wandb = None

warnings.filterwarnings('ignore')

# ==========================================================================================
# PATH SETUP
# ==========================================================================================
ROOT_DIR = Path(__file__).resolve().parents[3]
OUTPUT_DIR = ROOT_DIR / "outputs" / "Figures" / "panel_visualisation"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

SCRATCH = os.environ.get("SCRATCH")
candidate_paths = [
    Path(os.environ.get("PANEL_FILE", "")),
    Path(SCRATCH) / "data" / "ml" / "merged_panel_final.parquet" if SCRATCH else None,
    ROOT_DIR / "data" / "ml" / "merged_panel_final.parquet"
]
PANEL_FILE = next((p for p in candidate_paths if p and p.exists()), None)

if not PANEL_FILE:
    raise FileNotFoundError(f"Parquet not found. Searched: {[str(p) for p in candidate_paths if p]}")

# ==========================================================================================
# HELPERS
# ==========================================================================================
def q(name: str) -> str:
    """Standard DuckDB identifier quoting."""
    # Escape embedded quotes per SQL identifier rules: " -> ""
    return '"' + name.replace('"', '""') + '"'

def resolve_sample_method() -> str:
    raw = (os.environ.get("PANEL_VIS_SAMPLE_METHOD") or "system").lower()
    return "bernoulli" if "bern" in raw else "system"

def wb_log(data: dict):
    if wandb and wandb.run: wandb.log(data)

def wb_log_image(key: str, path: Path, caption: str):
    if wandb and wandb.run:
        try:
            wandb.log({key: wandb.Image(str(path), caption=caption)})
        except Exception as e:
            print(f"W&B Image Log Error: {e}")

# ==========================================================================================
# DUCKDB CONFIGURATION
# ==========================================================================================
def get_con():
    con = duckdb.connect()
    is_euler = bool(os.environ.get("SCRATCH"))
    cpus = int(os.environ.get("SLURM_CPUS_PER_TASK", "0"))
    threads = cpus if cpus > 0 else (48 if is_euler else 4)
    
    mem_mb = os.environ.get("SLURM_MEM_PER_CPU")
    limit_gb = (int(mem_mb) * cpus // 1024) if (mem_mb and cpus) else (128 if is_euler else 16)
    
    con.execute(f"SET threads={threads}")
    con.execute(f"SET memory_limit='{limit_gb}GB'")
    
    tmp = Path(os.environ.get("SCRATCH", ROOT_DIR)) / "duckdb_temp"
    tmp.mkdir(parents=True, exist_ok=True)
    con.execute(f"SET temp_directory='{tmp}'")
    return con

# ==========================================================================================
# TEMPORAL FEATURE COMPARISON (DEBUGGER)
# ==========================================================================================
def plot_temporal_feature_comparison(con, feature: str, years=[2011, 2013, 2015]):
    """Compare geography of a feature across 2011 (good), 2013 (crash), and 2015 (good)."""
    print(f"Creating Temporal Comparison for {feature}...")
    sample_pct = 2.0
    method = resolve_sample_method()
    
    # 1. Get global scale for comparability
    scale_query = f"""
    SELECT min({q(feature)}) as vmin, max({q(feature)}) as vmax 
    FROM read_parquet('{PANEL_FILE}') 
    USING SAMPLE 1% ({method})
    """
    stats = con.execute(scale_query).fetchone()
    # Apply 1/99 clipping logic
    clip_query = f"SELECT approx_quantile({q(feature)}, 0.01), approx_quantile({q(feature)}, 0.99) FROM read_parquet('{PANEL_FILE}')"
    vmin, vmax = con.execute(clip_query).fetchone()

    fig, axes = plt.subplots(1, 3, figsize=(20, 6), sharex=True, sharey=True)
    
    for i, year in enumerate(years):
        df = con.execute(f"""
            SELECT row, col, {q(feature)} as val 
            FROM read_parquet('{PANEL_FILE}') 
            WHERE year = {year} AND {q(feature)} IS NOT NULL
            USING SAMPLE {sample_pct}% ({method}) 
            LIMIT 300000
        """).df()
        
        ax = axes[i]
        if not df.empty:
            sc = ax.scatter(df['col'], df['row'], c=df['val'], s=0.1, 
                            cmap='viridis', vmin=vmin, vmax=vmax, rasterized=True)
            ax.set_title(f"Year {year} (n={len(df):,})", fontsize=12)
        else:
            ax.set_title(f"Year {year} (EMPTY)", color='red')
            
        ax.set_aspect('equal')

    plt.suptitle(f"Temporal Integrity Check: {feature} (2011 vs 2013 vs 2015)", fontsize=15, fontweight='bold')
    fig.subplots_adjust(right=0.92)
    cbar_ax = fig.add_axes([0.94, 0.15, 0.015, 0.7])
    fig.colorbar(plt.cm.ScalarMappable(norm=plt.Normalize(vmin, vmax), cmap='viridis'), cax=cbar_ax, label=feature)
    
    out_path = OUTPUT_DIR / f"integrity_temporal_comparison_{feature}.png"
    plt.savefig(out_path, dpi=300, bbox_inches='tight')
    plt.close()
    wb_log_image(f"plots/temporal_comp_{feature}", out_path, f"Temporal comparison for {feature}")

# ==========================================================================================
# STANDARD PLOTS (OPTIMIZED)
# ==========================================================================================
def plot_time_series(con, label_col):
    print("Creating time series...")
    query = f"""
        SELECT year, COUNT(*) AS rows, 
        {f"SUM(CASE WHEN {q(label_col)} = 1 THEN 1 ELSE 0 END)" if label_col else "0"} AS pos
        FROM read_parquet('{PANEL_FILE}') GROUP BY year ORDER BY year
    """
    df = con.execute(query).df()
    fig, ax1 = plt.subplots(figsize=(12, 6))
    ax1.plot(df['year'], df['rows'], color='tab:blue', marker='o', label='Total Rows')
    ax1.set_ylabel('Risk Set Size', color='tab:blue')
    if label_col:
        ax2 = ax1.twinx()
        ax2.bar(df['year'], df['pos'], color='tab:orange', alpha=0.4, label='Positives')
        ax2.set_ylabel('Positives', color='tab:orange')
    plt.title(f"Temporal Distribution (Highlighting 2012-2014 collapse)")
    out = OUTPUT_DIR / "time_series.png"
    plt.savefig(out, dpi=300); plt.close()
    return out

def plot_spatial_map(con, label_col):
    if not label_col: return None
    print("Creating spatial map...")
    # Pull bg and pos separately to ensure context
    bg = con.execute(f"SELECT row, col FROM read_parquet('{PANEL_FILE}') USING SAMPLE 0.5% LIMIT 200000").df()
    pos = con.execute(f"SELECT row, col FROM read_parquet('{PANEL_FILE}') WHERE {q(label_col)}=1 USING SAMPLE 5%").df()
    
    fig, ax = plt.subplots(figsize=(12, 10))
    ax.scatter(bg['col'], bg['row'], s=0.05, c='lightgray', alpha=0.1, rasterized=True)
    ax.scatter(pos['col'], pos['row'], s=0.5, c='red', alpha=0.5, rasterized=True)
    ax.set_aspect('equal')
    ax.set_title(f"Spatial Distribution of Positives ({label_col}=1)")
    out = OUTPUT_DIR / "spatial_map.png"
    plt.savefig(out, dpi=300); plt.close()
    return out

# ==========================================================================================
# MAIN EXECUTION
# ==========================================================================================
def main():
    print(f"Starting diagnostics for: {PANEL_FILE.name}")
    print(f"Absolute Output: {OUTPUT_DIR.resolve()}")
    
    con = get_con()
    
    # 1. Resolve Label
    schema = con.execute(f"DESCRIBE SELECT * FROM read_parquet('{PANEL_FILE}') LIMIT 0").df()
    cols = schema['column_name'].tolist()
    label_col = os.environ.get("LABEL_COL") or ("transition_01" if "transition_01" in cols else None)

    # 2. Start W&B
    if wandb:
        wandb.init(project="panel_visualisation", name=f"diag_{datetime.now().strftime('%m%d_%H%M')}")

    # 3. RUN NEW TEMPORAL COMPARISONS
    # Find feature with high variance to use for mapping
    numeric_cols = [c for c in cols if c not in ['year', 'x', 'y', 'row', 'col', label_col]]
    if numeric_cols:
        target_feat = "elevation_b1" if "elevation_b1" in numeric_cols else numeric_cols[0]
        plot_temporal_feature_comparison(con, target_feat)

    # 4. RUN STANDARD PLOTS
    plot_time_series(con, label_col)
    plot_spatial_map(con, label_col)
    
    print("="*50)
    print("DIAGNOSTICS COMPLETE")
    print("="*50)
    if wandb: wandb.finish()

if __name__ == "__main__":
    main()