
Configuration:
  WINDOW: 2 years
  Target column: transition_01_win2

Loaded metadata from /Users/gianluca/Desktop/Master's Thesis/code/data/ml/train_embeddings_win2_metadata.json
  Train years: 2018-2020
  Val years: 2021-2021
  Test years: 2022-2022
W&B connected
======================================================================
LGBM TRANSITION MODEL (EMBEDDINGS DATASET - 2-YEAR LOOKAHEAD)
======================================================================
Train: /Users/gianluca/Desktop/Master's Thesis/code/data/ml/train_embeddings_win2.parquet
Val: /Users/gianluca/Desktop/Master's Thesis/code/data/ml/val_embeddings_win2.parquet
Test: /Users/gianluca/Desktop/Master's Thesis/code/data/ml/test_embeddings_win2.parquet
Params: /Users/gianluca/Desktop/Master's Thesis/code/scripts/embeddings/ML/training/lgbm_best_params.json
Output: /Users/gianluca/Desktop/Master's Thesis/code/outputs/Results/ml_models

Loaded params from /Users/gianluca/Desktop/Master's Thesis/code/scripts/embeddings/ML/training/lgbm_best_params.json
Selected 64 features, loading 68 cols from train, 68 from test
Target column: transition_01_win2

======================================================================
PHASE 1: TRAINING
======================================================================

STEP A: LOAD TRAIN (2018-2020)

Loading train_embeddings_win2.parquet (two-pass NumPy loader)...
  Pass 1: Counting rows...
  Found 47,568,698 samples
  Pass 2: Pre-allocating arrays (47,568,698 samples, 64 features)...
  10 batches, 500,000/47,568,698 samples loaded
  20 batches, 1,000,000/47,568,698 samples loaded
  30 batches, 1,500,000/47,568,698 samples loaded
  40 batches, 2,000,000/47,568,698 samples loaded
  50 batches, 2,500,000/47,568,698 samples loaded
  60 batches, 3,000,000/47,568,698 samples loaded
  70 batches, 3,500,000/47,568,698 samples loaded
  80 batches, 4,000,000/47,568,698 samples loaded
  90 batches, 4,500,000/47,568,698 samples loaded
  100 batches, 5,000,000/47,568,698 samples loaded
  110 batches, 5,500,000/47,568,698 samples loaded
  120 batches, 6,000,000/47,568,698 samples loaded
  130 batches, 6,500,000/47,568,698 samples loaded
  140 batches, 7,000,000/47,568,698 samples loaded
  150 batches, 7,500,000/47,568,698 samples loaded
  160 batches, 8,000,000/47,568,698 samples loaded
  170 batches, 8,500,000/47,568,698 samples loaded
  180 batches, 9,000,000/47,568,698 samples loaded
  190 batches, 9,500,000/47,568,698 samples loaded
  200 batches, 10,000,000/47,568,698 samples loaded
  210 batches, 10,500,000/47,568,698 samples loaded
  220 batches, 11,000,000/47,568,698 samples loaded
  230 batches, 11,500,000/47,568,698 samples loaded
  240 batches, 12,000,000/47,568,698 samples loaded
  250 batches, 12,500,000/47,568,698 samples loaded
  260 batches, 13,000,000/47,568,698 samples loaded
  270 batches, 13,500,000/47,568,698 samples loaded
  280 batches, 14,000,000/47,568,698 samples loaded
  290 batches, 14,500,000/47,568,698 samples loaded
  300 batches, 15,000,000/47,568,698 samples loaded
  310 batches, 15,500,000/47,568,698 samples loaded
  320 batches, 16,000,000/47,568,698 samples loaded
  330 batches, 16,500,000/47,568,698 samples loaded
  340 batches, 17,000,000/47,568,698 samples loaded
  350 batches, 17,500,000/47,568,698 samples loaded
