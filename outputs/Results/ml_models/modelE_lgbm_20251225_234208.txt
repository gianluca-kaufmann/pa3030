W&B connected
======================================================================
LGBM TRANSITION MODEL (EMBEDDINGS DATASET)
======================================================================
Train: /Users/gianluca/Desktop/Master's Thesis/code/data/ml/train_embeddings.parquet
Val: /Users/gianluca/Desktop/Master's Thesis/code/data/ml/val_embeddings.parquet
Test: /Users/gianluca/Desktop/Master's Thesis/code/data/ml/test_embeddings.parquet
Params: /Users/gianluca/Desktop/Master's Thesis/code/scripts/embeddings/ML/training/lgbm_best_params.json
Output: /Users/gianluca/Desktop/Master's Thesis/code/outputs/Results/ml_models

Loaded params from /Users/gianluca/Desktop/Master's Thesis/code/scripts/embeddings/ML/training/lgbm_best_params.json
Selected 64 features, loading 68 cols from train, 68 from test

======================================================================
PHASE 1: TRAINING
======================================================================

STEP A: LOAD TRAIN (2018-2021)

Loading train_embeddings.parquet (two-pass NumPy loader)...
  Pass 1: Counting rows...
  Found 63,350,953 samples
  Pass 2: Pre-allocating arrays (63,350,953 samples, 64 features)...
  10 batches, 500,000/63,350,953 samples loaded
  20 batches, 1,000,000/63,350,953 samples loaded
  30 batches, 1,500,000/63,350,953 samples loaded
  40 batches, 2,000,000/63,350,953 samples loaded
  50 batches, 2,500,000/63,350,953 samples loaded
  60 batches, 3,000,000/63,350,953 samples loaded
  70 batches, 3,500,000/63,350,953 samples loaded
  80 batches, 4,000,000/63,350,953 samples loaded
  90 batches, 4,500,000/63,350,953 samples loaded
  100 batches, 5,000,000/63,350,953 samples loaded
  110 batches, 5,500,000/63,350,953 samples loaded
  120 batches, 6,000,000/63,350,953 samples loaded
  130 batches, 6,500,000/63,350,953 samples loaded
  140 batches, 7,000,000/63,350,953 samples loaded
  150 batches, 7,500,000/63,350,953 samples loaded
  160 batches, 8,000,000/63,350,953 samples loaded
  170 batches, 8,500,000/63,350,953 samples loaded
  180 batches, 9,000,000/63,350,953 samples loaded
  190 batches, 9,500,000/63,350,953 samples loaded
  200 batches, 10,000,000/63,350,953 samples loaded
  210 batches, 10,500,000/63,350,953 samples loaded
  220 batches, 11,000,000/63,350,953 samples loaded
  230 batches, 11,500,000/63,350,953 samples loaded
  240 batches, 12,000,000/63,350,953 samples loaded
  250 batches, 12,500,000/63,350,953 samples loaded
  260 batches, 13,000,000/63,350,953 samples loaded
  270 batches, 13,500,000/63,350,953 samples loaded
  280 batches, 14,000,000/63,350,953 samples loaded
  290 batches, 14,500,000/63,350,953 samples loaded
  300 batches, 15,000,000/63,350,953 samples loaded
  310 batches, 15,500,000/63,350,953 samples loaded
  320 batches, 16,000,000/63,350,953 samples loaded
  330 batches, 16,500,000/63,350,953 samples loaded
  340 batches, 17,000,000/63,350,953 samples loaded
  350 batches, 17,500,000/63,350,953 samples loaded
  360 batches, 18,000,000/63,350,953 samples loaded
  370 batches, 18,500,000/63,350,953 samples loaded
  380 batches, 19,000,000/63,350,953 samples loaded
  390 batches, 19,500,000/63,350,953 samples loaded
  400 batches, 20,000,000/63,350,953 samples loaded
  410 batches, 20,500,000/63,350,953 samples loaded
  420 batches, 21,000,000/63,350,953 samples loaded
  430 batches, 21,500,000/63,350,953 samples loaded
  440 batches, 22,000,000/63,350,953 samples loaded
  450 batches, 22,500,000/63,350,953 samples loaded
  460 batches, 23,000,000/63,350,953 samples loaded
  470 batches, 23,500,000/63,350,953 samples loaded
  480 batches, 24,000,000/63,350,953 samples loaded
  490 batches, 24,500,000/63,350,953 samples loaded
  500 batches, 25,000,000/63,350,953 samples loaded
  510 batches, 25,500,000/63,350,953 samples loaded
  520 batches, 26,000,000/63,350,953 samples loaded
  530 batches, 26,500,000/63,350,953 samples loaded
  540 batches, 27,000,000/63,350,953 samples loaded
  550 batches, 27,500,000/63,350,953 samples loaded
  560 batches, 28,000,000/63,350,953 samples loaded
  570 batches, 28,500,000/63,350,953 samples loaded
  580 batches, 29,000,000/63,350,953 samples loaded
  590 batches, 29,500,000/63,350,953 samples loaded
  600 batches, 30,000,000/63,350,953 samples loaded
  610 batches, 30,500,000/63,350,953 samples loaded
  620 batches, 31,000,000/63,350,953 samples loaded
  630 batches, 31,500,000/63,350,953 samples loaded
  640 batches, 32,000,000/63,350,953 samples loaded
  650 batches, 32,500,000/63,350,953 samples loaded
  660 batches, 33,000,000/63,350,953 samples loaded
  670 batches, 33,500,000/63,350,953 samples loaded
  680 batches, 34,000,000/63,350,953 samples loaded
  690 batches, 34,500,000/63,350,953 samples loaded
  700 batches, 35,000,000/63,350,953 samples loaded
  710 batches, 35,500,000/63,350,953 samples loaded
  720 batches, 36,000,000/63,350,953 samples loaded
  730 batches, 36,500,000/63,350,953 samples loaded
  740 batches, 37,000,000/63,350,953 samples loaded
  750 batches, 37,500,000/63,350,953 samples loaded
  760 batches, 38,000,000/63,350,953 samples loaded
  770 batches, 38,500,000/63,350,953 samples loaded
  780 batches, 39,000,000/63,350,953 samples loaded
  790 batches, 39,500,000/63,350,953 samples loaded
  800 batches, 40,000,000/63,350,953 samples loaded
  810 batches, 40,500,000/63,350,953 samples loaded
  820 batches, 41,000,000/63,350,953 samples loaded
  830 batches, 41,500,000/63,350,953 samples loaded
  840 batches, 42,000,000/63,350,953 samples loaded
  850 batches, 42,500,000/63,350,953 samples loaded
  860 batches, 43,000,000/63,350,953 samples loaded
  870 batches, 43,500,000/63,350,953 samples loaded
  880 batches, 44,000,000/63,350,953 samples loaded
  890 batches, 44,500,000/63,350,953 samples loaded
  900 batches, 45,000,000/63,350,953 samples loaded
  910 batches, 45,500,000/63,350,953 samples loaded
  920 batches, 46,000,000/63,350,953 samples loaded
  930 batches, 46,500,000/63,350,953 samples loaded
  940 batches, 47,000,000/63,350,953 samples loaded
  950 batches, 47,500,000/63,350,953 samples loaded
  960 batches, 48,000,000/63,350,953 samples loaded
  970 batches, 48,500,000/63,350,953 samples loaded
  980 batches, 49,000,000/63,350,953 samples loaded
  990 batches, 49,500,000/63,350,953 samples loaded
  1000 batches, 50,000,000/63,350,953 samples loaded
  1010 batches, 50,500,000/63,350,953 samples loaded
  1020 batches, 51,000,000/63,350,953 samples loaded
  1030 batches, 51,500,000/63,350,953 samples loaded
  1040 batches, 52,000,000/63,350,953 samples loaded
  1050 batches, 52,500,000/63,350,953 samples loaded
  1060 batches, 53,000,000/63,350,953 samples loaded
  1070 batches, 53,500,000/63,350,953 samples loaded
  1080 batches, 54,000,000/63,350,953 samples loaded
  1090 batches, 54,500,000/63,350,953 samples loaded
  1100 batches, 55,000,000/63,350,953 samples loaded
  1110 batches, 55,500,000/63,350,953 samples loaded
  1120 batches, 56,000,000/63,350,953 samples loaded
  1130 batches, 56,500,000/63,350,953 samples loaded
  1140 batches, 57,000,000/63,350,953 samples loaded
  1150 batches, 57,500,000/63,350,953 samples loaded
  1160 batches, 58,000,000/63,350,953 samples loaded
  1170 batches, 58,500,000/63,350,953 samples loaded
  1180 batches, 59,000,000/63,350,953 samples loaded
  1190 batches, 59,500,000/63,350,953 samples loaded
  1200 batches, 60,000,000/63,350,953 samples loaded
  1210 batches, 60,500,000/63,350,953 samples loaded
  1220 batches, 61,000,000/63,350,953 samples loaded
  1230 batches, 61,500,000/63,350,953 samples loaded
  1240 batches, 62,000,000/63,350,953 samples loaded
  1250 batches, 62,500,000/63,350,953 samples loaded
  1260 batches, 63,000,000/63,350,953 samples loaded
  Loaded 63,350,953 rows in 61.4s (15.16 GB)
  63,192,877 neg, 158,076 pos, ratio 1:399.8, years 2018-2021

STEP B: LOAD VAL (2022)

Loading val_embeddings.parquet (two-pass NumPy loader)...
  Pass 1: Counting rows...
  Found 15,766,956 samples
  Pass 2: Pre-allocating arrays (15,766,956 samples, 64 features)...
  10 batches, 500,000/15,766,956 samples loaded
  20 batches, 1,000,000/15,766,956 samples loaded
  30 batches, 1,500,000/15,766,956 samples loaded
  40 batches, 2,000,000/15,766,956 samples loaded
  50 batches, 2,500,000/15,766,956 samples loaded
  60 batches, 3,000,000/15,766,956 samples loaded
  70 batches, 3,500,000/15,766,956 samples loaded
  80 batches, 4,000,000/15,766,956 samples loaded
  90 batches, 4,500,000/15,766,956 samples loaded
  100 batches, 5,000,000/15,766,956 samples loaded
  110 batches, 5,500,000/15,766,956 samples loaded
  120 batches, 6,000,000/15,766,956 samples loaded
  130 batches, 6,500,000/15,766,956 samples loaded
  140 batches, 7,000,000/15,766,956 samples loaded
  150 batches, 7,500,000/15,766,956 samples loaded
  160 batches, 8,000,000/15,766,956 samples loaded
  170 batches, 8,500,000/15,766,956 samples loaded
  180 batches, 9,000,000/15,766,956 samples loaded
  190 batches, 9,500,000/15,766,956 samples loaded
  200 batches, 10,000,000/15,766,956 samples loaded
  210 batches, 10,500,000/15,766,956 samples loaded
  220 batches, 11,000,000/15,766,956 samples loaded
  230 batches, 11,500,000/15,766,956 samples loaded
  240 batches, 12,000,000/15,766,956 samples loaded
  250 batches, 12,500,000/15,766,956 samples loaded
  260 batches, 13,000,000/15,766,956 samples loaded
  270 batches, 13,500,000/15,766,956 samples loaded
  280 batches, 14,000,000/15,766,956 samples loaded
  290 batches, 14,500,000/15,766,956 samples loaded
  300 batches, 15,000,000/15,766,956 samples loaded
  310 batches, 15,500,000/15,766,956 samples loaded
  Loaded 15,766,956 rows in 17.2s (3.77 GB)
  15,735,365 neg, 31,591 pos, ratio 1:498.1, years 2022-2022

STEP C: TRAIN & EVALUATE
Temporal split: train (2018-2021): 63,350,953 rows, val (2022): 15,766,956 rows

Imbalance: ratio 399.763, scale_pos_weight 399.762627 (n_neg/n_pos from TRAIN)

Training on train (63,350,953 samples)...
  Creating train dataset...
  Creating validation dataset...
  Starting training...
Training until validation scores don't improve for 500 rounds
[100]	val's average_precision: 0.00208113
[200]	val's average_precision: 0.00387294
[300]	val's average_precision: 0.00174895
[400]	val's average_precision: 0.0016997
[500]	val's average_precision: 0.00306047
Early stopping, best iteration is:
[6]	val's average_precision: 0.010239

Training done in 1698.8s. Best iteration: 6

Validation: ROC-AUC 0.7203, PR-AUC 0.0102, P@1% 0.0049, P@5% 0.0169, P@10% 0.0093
Model saved: /Users/gianluca/Desktop/Master's Thesis/code/data/ml/models/modelE_lgbm_20251225_234208.pkl
Phase 1 completed.

======================================================================
PHASE 2: TESTING
======================================================================

Loading model from /Users/gianluca/Desktop/Master's Thesis/code/data/ml/models/modelE_lgbm_20251225_234208.pkl
Processing test in batches of 50,000...
  Pass 1: Counting test rows...
  Found 31,462,608 test samples
  Pre-allocating arrays for 31,462,608 samples...
Writing to /Users/gianluca/Desktop/Master's Thesis/code/outputs/Results/ml_models/modelE_lgbm_scored_20251225_234208.parquet
  10 batches, 500,000/31,462,608 rows
  20 batches, 1,000,000/31,462,608 rows
  30 batches, 1,500,000/31,462,608 rows
  40 batches, 2,000,000/31,462,608 rows
  50 batches, 2,500,000/31,462,608 rows
  60 batches, 3,000,000/31,462,608 rows
  70 batches, 3,500,000/31,462,608 rows
  80 batches, 4,000,000/31,462,608 rows
  90 batches, 4,500,000/31,462,608 rows
  100 batches, 5,000,000/31,462,608 rows
  110 batches, 5,500,000/31,462,608 rows
  120 batches, 6,000,000/31,462,608 rows
  130 batches, 6,500,000/31,462,608 rows
  140 batches, 7,000,000/31,462,608 rows
  150 batches, 7,500,000/31,462,608 rows
  160 batches, 8,000,000/31,462,608 rows
  170 batches, 8,500,000/31,462,608 rows
  180 batches, 9,000,000/31,462,608 rows
  190 batches, 9,500,000/31,462,608 rows
  200 batches, 10,000,000/31,462,608 rows
  210 batches, 10,500,000/31,462,608 rows
  220 batches, 11,000,000/31,462,608 rows
  230 batches, 11,500,000/31,462,608 rows
  240 batches, 12,000,000/31,462,608 rows
  250 batches, 12,500,000/31,462,608 rows
  260 batches, 13,000,000/31,462,608 rows
  270 batches, 13,500,000/31,462,608 rows
  280 batches, 14,000,000/31,462,608 rows
  290 batches, 14,500,000/31,462,608 rows
  300 batches, 15,000,000/31,462,608 rows
  310 batches, 15,500,000/31,462,608 rows
  320 batches, 16,000,000/31,462,608 rows
  330 batches, 16,500,000/31,462,608 rows
  340 batches, 17,000,000/31,462,608 rows
  350 batches, 17,500,000/31,462,608 rows
  360 batches, 18,000,000/31,462,608 rows
  370 batches, 18,500,000/31,462,608 rows
  380 batches, 19,000,000/31,462,608 rows
  390 batches, 19,500,000/31,462,608 rows
  400 batches, 20,000,000/31,462,608 rows
  410 batches, 20,500,000/31,462,608 rows
  420 batches, 21,000,000/31,462,608 rows
  430 batches, 21,500,000/31,462,608 rows
  440 batches, 22,000,000/31,462,608 rows
  450 batches, 22,500,000/31,462,608 rows
  460 batches, 23,000,000/31,462,608 rows
  470 batches, 23,500,000/31,462,608 rows
  480 batches, 24,000,000/31,462,608 rows
  490 batches, 24,500,000/31,462,608 rows
  500 batches, 25,000,000/31,462,608 rows
  510 batches, 25,500,000/31,462,608 rows
  520 batches, 26,000,000/31,462,608 rows
  530 batches, 26,500,000/31,462,608 rows
  540 batches, 27,000,000/31,462,608 rows
  550 batches, 27,500,000/31,462,608 rows
  560 batches, 28,000,000/31,462,608 rows
  570 batches, 28,500,000/31,462,608 rows
  580 batches, 29,000,000/31,462,608 rows
  590 batches, 29,500,000/31,462,608 rows
  600 batches, 30,000,000/31,462,608 rows
  610 batches, 30,500,000/31,462,608 rows
  620 batches, 31,000,000/31,462,608 rows
  630 batches, 31,462,608/31,462,608 rows
Completed 630 batches in 28.5s, 31,462,608 rows

Test set: 31,452,858 neg, 9,750 pos, ratio 1:3225.9, years 2023-2024

Test metrics: ROC-AUC 0.3690, PR-AUC 0.0003
  P@1%: 0.0003 (96/314,626), lift 0.98x
  P@5%: 0.0003 (396/1,573,130), lift 0.81x
  P@10%: 0.0003 (961/3,146,260), lift 0.99x

Top 20 features:
feature  importance
 emb_45          22
 emb_04          19
 emb_28          15
 emb_22          14
 emb_41          12
 emb_57          12
 emb_55          11
 emb_44          11
 emb_52          11
 emb_47          10
 emb_32          10
 emb_31          10
 emb_21          10
 emb_42          10
 emb_29           8
 emb_24           8
 emb_64           8
 emb_56           7
 emb_62           7
 emb_06           7

Metrics saved: /Users/gianluca/Desktop/Master's Thesis/code/outputs/Results/ml_models/modelE_lgbm_metrics_20251225_234208.json

======================================================================
SUMMARY
======================================================================
Model: LightGBM, 64 features
Validation (2018-2021â†’2022): PR-AUC 0.0102, ROC-AUC 0.7203
Test (2023-2024, 31,462,608 samples, 0.031% pos): ROC-AUC 0.3690, PR-AUC 0.0003
  P@1%: 0.0003 (1.0x), P@5%: 0.0003 (0.8x), P@10%: 0.0003 (1.0x)
Timings: train 1698.8s, val 5.0s, pred 28.5s, total 1827.9s (30.5m)
======================================================================
Done.
