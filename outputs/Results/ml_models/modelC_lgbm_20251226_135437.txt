W&B connected
======================================================================
LGBM TRANSITION MODEL (COLOMBIA DATASET)
======================================================================
Train: /Users/gianluca/Desktop/Master's Thesis/code/data/ml/train_colombia.parquet
Val: /Users/gianluca/Desktop/Master's Thesis/code/data/ml/val_colombia.parquet
Test: /Users/gianluca/Desktop/Master's Thesis/code/data/ml/test_colombia.parquet
Params: /Users/gianluca/Desktop/Master's Thesis/code/scripts/colombia/ML/training/lgbm_best_params.json
Output: /Users/gianluca/Desktop/Master's Thesis/code/outputs/Results/ml_models

Loaded params from /Users/gianluca/Desktop/Master's Thesis/code/scripts/colombia/ML/training/lgbm_best_params.json
Best CV score: 0.0911
Selected 60 features, loading 66 cols from train, 66 from test

======================================================================
PHASE 1: TRAINING
======================================================================

STEP A: LOAD TRAIN (2000-2014)

Loading train_colombia.parquet (two-pass NumPy loader)...
  Pass 1: Counting rows...
  Found 15,206,524 samples
  Pass 2: Pre-allocating arrays (15,206,524 samples, 60 features)...
  10 batches, 500,000/15,206,524 samples loaded
  20 batches, 1,000,000/15,206,524 samples loaded
  30 batches, 1,500,000/15,206,524 samples loaded
  40 batches, 2,000,000/15,206,524 samples loaded
  50 batches, 2,500,000/15,206,524 samples loaded
  60 batches, 3,000,000/15,206,524 samples loaded
  70 batches, 3,500,000/15,206,524 samples loaded
  80 batches, 4,000,000/15,206,524 samples loaded
  90 batches, 4,500,000/15,206,524 samples loaded
  100 batches, 5,000,000/15,206,524 samples loaded
  110 batches, 5,500,000/15,206,524 samples loaded
  120 batches, 6,000,000/15,206,524 samples loaded
  130 batches, 6,500,000/15,206,524 samples loaded
  140 batches, 7,000,000/15,206,524 samples loaded
  150 batches, 7,500,000/15,206,524 samples loaded
  160 batches, 8,000,000/15,206,524 samples loaded
  170 batches, 8,500,000/15,206,524 samples loaded
  180 batches, 9,000,000/15,206,524 samples loaded
  190 batches, 9,500,000/15,206,524 samples loaded
  200 batches, 10,000,000/15,206,524 samples loaded
  210 batches, 10,500,000/15,206,524 samples loaded
  220 batches, 11,000,000/15,206,524 samples loaded
  230 batches, 11,500,000/15,206,524 samples loaded
  240 batches, 12,000,000/15,206,524 samples loaded
  250 batches, 12,500,000/15,206,524 samples loaded
  260 batches, 13,000,000/15,206,524 samples loaded
  270 batches, 13,500,000/15,206,524 samples loaded
  280 batches, 14,000,000/15,206,524 samples loaded
  290 batches, 14,500,000/15,206,524 samples loaded
  300 batches, 15,000,000/15,206,524 samples loaded
  Loaded 15,206,524 rows in 16.3s (3.41 GB)
  15,028,264 neg, 178,260 pos, ratio 1:84.3, years 2000-2014

STEP B: LOAD VAL (2015-2017)

Loading val_colombia.parquet (two-pass NumPy loader)...
  Pass 1: Counting rows...
  Found 2,940,252 samples
  Pass 2: Pre-allocating arrays (2,940,252 samples, 60 features)...
  10 batches, 500,000/2,940,252 samples loaded
  20 batches, 1,000,000/2,940,252 samples loaded
  30 batches, 1,500,000/2,940,252 samples loaded
  40 batches, 2,000,000/2,940,252 samples loaded
  50 batches, 2,500,000/2,940,252 samples loaded
  Loaded 2,940,252 rows in 2.9s (0.66 GB)
  2,933,941 neg, 6,311 pos, ratio 1:464.9, years 2015-2017

STEP C: TRAIN & EVALUATE
Temporal split: train (2000-2014): 15,206,524 rows, val (2015-2017): 2,940,252 rows

Imbalance: ratio 84.305, scale_pos_weight 200.000000 (from JSON params)

Training on train (15,206,524 samples)...
  Creating train dataset...
  Creating validation dataset...
  Starting training...
Training until validation scores don't improve for 500 rounds
[100]	val's average_precision: 0.0146731
[200]	val's average_precision: 0.0148298
[300]	val's average_precision: 0.0142939
[400]	val's average_precision: 0.0138017
[500]	val's average_precision: 0.0136102
Early stopping, best iteration is:
[27]	val's average_precision: 0.0154947

Training done in 233.5s. Best iteration: 27

Validation: ROC-AUC 0.8694, PR-AUC 0.0155, P@1% 0.0199, P@5% 0.0210, P@10% 0.0128
Model saved: /Users/gianluca/Desktop/Master's Thesis/code/data/ml/models/modelC_lgbm_20251226_135437.pkl
Phase 1 completed.

======================================================================
PHASE 2: TESTING
======================================================================

Loading model from /Users/gianluca/Desktop/Master's Thesis/code/data/ml/models/modelC_lgbm_20251226_135437.pkl
Processing test in batches of 50,000...
  Pass 1: Counting test rows...
  Found 6,757,920 test samples
  Pre-allocating arrays for 6,757,920 samples...
Writing to /Users/gianluca/Desktop/Master's Thesis/code/outputs/Results/ml_models/modelC_lgbm_scored_20251226_135437.parquet
  10 batches, 500,000/6,757,920 rows
  20 batches, 1,000,000/6,757,920 rows
  30 batches, 1,500,000/6,757,920 rows
  40 batches, 2,000,000/6,757,920 rows
  50 batches, 2,500,000/6,757,920 rows
  60 batches, 3,000,000/6,757,920 rows
  70 batches, 3,500,000/6,757,920 rows
  80 batches, 4,000,000/6,757,920 rows
  90 batches, 4,500,000/6,757,920 rows
  100 batches, 5,000,000/6,757,920 rows
  110 batches, 5,500,000/6,757,920 rows
  120 batches, 6,000,000/6,757,920 rows
  130 batches, 6,500,000/6,757,920 rows
Completed 136 batches in 6.6s, 6,757,920 rows

Test set: 6,741,895 neg, 16,025 pos, ratio 1:420.7, years 2018-2024

Test metrics: ROC-AUC 0.6473, PR-AUC 0.0040
  P@1%: 0.0070 (475/67,579), lift 2.96x
  P@5%: 0.0047 (1,605/337,896), lift 2.00x
  P@10%: 0.0041 (2,737/675,792), lift 1.71x

Top 20 features:
                  feature  importance
          GSN_b2_smooth16          29
     wildfire_b1_smooth64          27
deforestation_b1_smooth64          25
                   GPW_b1          23
                dist_wdpa          22
         NDVI_b1_smooth64          17
            WorldClim_b14          16
          GSN_b2_smooth64          14
         NDVI_b1_smooth16          13
             WorldClim_b7          13
         HNTL_b1_smooth64          11
          dist_powerplant          11
             landcover_b1          10
          GSN_b4_smooth64           9
            WorldClim_b17           9
                   GSN_b2           8
             WorldClim_b8           8
          GPW_b1_smooth64           7
                  NDVI_b1           7
            WorldClim_b15           7

Metrics saved: /Users/gianluca/Desktop/Master's Thesis/code/outputs/Results/ml_models/modelC_lgbm_metrics_20251226_135437.json

======================================================================
SUMMARY
======================================================================
Model: LightGBM, 60 features
Validation (2000-2014â†’2015-2017): PR-AUC 0.0155, ROC-AUC 0.8694
Test (2018-2024, 6,757,920 samples, 0.237% pos): ROC-AUC 0.6473, PR-AUC 0.0040
  P@1%: 0.0070 (3.0x), P@5%: 0.0047 (2.0x), P@10%: 0.0041 (1.7x)
Timings: train 233.5s, val 0.5s, pred 6.6s, total 264.9s (4.4m)
======================================================================
Done.
