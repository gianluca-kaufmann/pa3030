W&B connected
======================================================================
LGBM TRANSITION MODEL (COLOMBIA DATASET)
======================================================================
Train: /Users/gianluca/Desktop/Master's Thesis/code/data/ml/train_colombia.parquet
Val: /Users/gianluca/Desktop/Master's Thesis/code/data/ml/val_colombia.parquet
Test: /Users/gianluca/Desktop/Master's Thesis/code/data/ml/test_colombia.parquet
Params: /Users/gianluca/Desktop/Master's Thesis/code/scripts/colombia/ML/training/lgbm_best_params.json
Output: /Users/gianluca/Desktop/Master's Thesis/code/outputs/Results/ml_models

Loaded params from /Users/gianluca/Desktop/Master's Thesis/code/scripts/colombia/ML/training/lgbm_best_params.json
Best CV score: 0.0911
Selected 60 features, loading 66 cols from train, 66 from test

======================================================================
PHASE 1: TRAINING
======================================================================

STEP A: LOAD TRAIN (2000-2014)

Loading train_colombia.parquet (two-pass NumPy loader)...
  Pass 1: Counting rows...
  Found 15,206,524 samples
  Pass 2: Pre-allocating arrays (15,206,524 samples, 60 features)...
  10 batches, 500,000/15,206,524 samples loaded
  20 batches, 1,000,000/15,206,524 samples loaded
  30 batches, 1,500,000/15,206,524 samples loaded
  40 batches, 2,000,000/15,206,524 samples loaded
  50 batches, 2,500,000/15,206,524 samples loaded
  60 batches, 3,000,000/15,206,524 samples loaded
  70 batches, 3,500,000/15,206,524 samples loaded
  80 batches, 4,000,000/15,206,524 samples loaded
  90 batches, 4,500,000/15,206,524 samples loaded
  100 batches, 5,000,000/15,206,524 samples loaded
  110 batches, 5,500,000/15,206,524 samples loaded
  120 batches, 6,000,000/15,206,524 samples loaded
  130 batches, 6,500,000/15,206,524 samples loaded
  140 batches, 7,000,000/15,206,524 samples loaded
  150 batches, 7,500,000/15,206,524 samples loaded
  160 batches, 8,000,000/15,206,524 samples loaded
  170 batches, 8,500,000/15,206,524 samples loaded
  180 batches, 9,000,000/15,206,524 samples loaded
  190 batches, 9,500,000/15,206,524 samples loaded
  200 batches, 10,000,000/15,206,524 samples loaded
  210 batches, 10,500,000/15,206,524 samples loaded
  220 batches, 11,000,000/15,206,524 samples loaded
  230 batches, 11,500,000/15,206,524 samples loaded
  240 batches, 12,000,000/15,206,524 samples loaded
  250 batches, 12,500,000/15,206,524 samples loaded
  260 batches, 13,000,000/15,206,524 samples loaded
  270 batches, 13,500,000/15,206,524 samples loaded
  280 batches, 14,000,000/15,206,524 samples loaded
  290 batches, 14,500,000/15,206,524 samples loaded
  300 batches, 15,000,000/15,206,524 samples loaded
  Loaded 15,206,524 rows in 18.1s (3.41 GB)
  15,028,264 neg, 178,260 pos, ratio 1:84.3, years 2000-2014

STEP B: LOAD VAL (2015-2017)

Loading val_colombia.parquet (two-pass NumPy loader)...
  Pass 1: Counting rows...
  Found 2,940,252 samples
  Pass 2: Pre-allocating arrays (2,940,252 samples, 60 features)...
  10 batches, 500,000/2,940,252 samples loaded
  20 batches, 1,000,000/2,940,252 samples loaded
  30 batches, 1,500,000/2,940,252 samples loaded
  40 batches, 2,000,000/2,940,252 samples loaded
  50 batches, 2,500,000/2,940,252 samples loaded
  Loaded 2,940,252 rows in 2.8s (0.66 GB)
  2,933,941 neg, 6,311 pos, ratio 1:464.9, years 2015-2017

STEP C: TRAIN & EVALUATE
Temporal split: train (2000-2014): 15,206,524 rows, val (2015-2017): 2,940,252 rows

Imbalance: ratio 84.305, scale_pos_weight 10.000000 (from JSON params)

Training on train (15,206,524 samples)...
  Creating train dataset...
  Creating validation dataset...
  Starting training...
Training until validation scores don't improve for 500 rounds
[100]	val's average_precision: 0.0153507
[200]	val's average_precision: 0.0128025
[300]	val's average_precision: 0.011905
[400]	val's average_precision: 0.0113631
[500]	val's average_precision: 0.0107283
Early stopping, best iteration is:
[55]	val's average_precision: 0.0159249

Training done in 360.0s. Best iteration: 55

Validation: ROC-AUC 0.8568, PR-AUC 0.0159, P@1% 0.0258, P@5% 0.0144, P@10% 0.0107
Model saved: /Users/gianluca/Desktop/Master's Thesis/code/data/ml/models/modelC_lgbm_20251226_140517.pkl
Phase 1 completed.

======================================================================
PHASE 2: TESTING
======================================================================

Loading model from /Users/gianluca/Desktop/Master's Thesis/code/data/ml/models/modelC_lgbm_20251226_140517.pkl
Processing test in batches of 50,000...
  Pass 1: Counting test rows...
  Found 6,757,920 test samples
  Pre-allocating arrays for 6,757,920 samples...
Writing to /Users/gianluca/Desktop/Master's Thesis/code/outputs/Results/ml_models/modelC_lgbm_scored_20251226_140517.parquet
  10 batches, 500,000/6,757,920 rows
  20 batches, 1,000,000/6,757,920 rows
  30 batches, 1,500,000/6,757,920 rows
  40 batches, 2,000,000/6,757,920 rows
  50 batches, 2,500,000/6,757,920 rows
  60 batches, 3,000,000/6,757,920 rows
  70 batches, 3,500,000/6,757,920 rows
  80 batches, 4,000,000/6,757,920 rows
  90 batches, 4,500,000/6,757,920 rows
  100 batches, 5,000,000/6,757,920 rows
  110 batches, 5,500,000/6,757,920 rows
  120 batches, 6,000,000/6,757,920 rows
  130 batches, 6,500,000/6,757,920 rows
Completed 136 batches in 13.0s, 6,757,920 rows

Test set: 6,741,895 neg, 16,025 pos, ratio 1:420.7, years 2018-2024

Test metrics: ROC-AUC 0.7110, PR-AUC 0.0046
  P@1%: 0.0058 (391/67,579), lift 2.44x
  P@5%: 0.0065 (2,204/337,896), lift 2.75x
  P@10%: 0.0052 (3,506/675,792), lift 2.19x

Top 20 features:
                  feature  importance
deforestation_b1_smooth64         522
         NDVI_b1_smooth64         506
          dist_powerplant         376
                dist_wdpa         290
                   GPW_b1         280
         HNTL_b1_smooth64         238
     wildfire_b1_smooth64         229
          GSN_b2_smooth16         224
          GSN_b4_smooth64         206
          GSN_b2_smooth64         205
         NDVI_b1_smooth16         203
          GSN_b5_smooth64         189
deforestation_b1_smooth16         170
             WorldClim_b7         165
             WorldClim_b6         161
          GPW_b1_smooth64         159
             dist_oil_gas         158
             WorldClim_b5         141
             WorldClim_b8         137
            WorldClim_b11         133

Metrics saved: /Users/gianluca/Desktop/Master's Thesis/code/outputs/Results/ml_models/modelC_lgbm_metrics_20251226_140517.json

======================================================================
SUMMARY
======================================================================
Model: LightGBM, 60 features
Validation (2000-2014â†’2015-2017): PR-AUC 0.0159, ROC-AUC 0.8568
Test (2018-2024, 6,757,920 samples, 0.237% pos): ROC-AUC 0.7110, PR-AUC 0.0046
  P@1%: 0.0058 (2.4x), P@5%: 0.0065 (2.8x), P@10%: 0.0052 (2.2x)
Timings: train 360.0s, val 1.6s, pred 13.0s, total 402.1s (6.7m)
======================================================================
Done.
